{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "badb7797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import normalize,StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, GridSearchCV,train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss,roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.calibration import calibration_curve\n",
    "from xgboost import XGBClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcf644c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tscore_Hip_total</th>\n",
       "      <th>CRP</th>\n",
       "      <th>Cr</th>\n",
       "      <th>ALP</th>\n",
       "      <th>BUN</th>\n",
       "      <th>P</th>\n",
       "      <th>Ca</th>\n",
       "      <th>PTH</th>\n",
       "      <th>...</th>\n",
       "      <th>BMD_Hip_Neck</th>\n",
       "      <th>Tscore_Hip_neck</th>\n",
       "      <th>Zscore_Hip_neck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Histroy_Anticoagulant</th>\n",
       "      <th>Active_Smoking</th>\n",
       "      <th>History_Smoking</th>\n",
       "      <th>Calcium_Supplement</th>\n",
       "      <th>History_Diabetes_2</th>\n",
       "      <th>Refracture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>28.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75200</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>40.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0384</td>\n",
       "      <td>236.983784</td>\n",
       "      <td>17.019137</td>\n",
       "      <td>3.505219</td>\n",
       "      <td>8.627989</td>\n",
       "      <td>50.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.73400</td>\n",
       "      <td>-1.400000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>15.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.68900</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>38.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>50.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65400</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>38.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>66.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.02700</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>36.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>383</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>35.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72300</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>384</td>\n",
       "      <td>59</td>\n",
       "      <td>-0.543658</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>35.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.69818</td>\n",
       "      <td>-1.579244</td>\n",
       "      <td>-0.513953</td>\n",
       "      <td>26.170573</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>385</td>\n",
       "      <td>64</td>\n",
       "      <td>-0.543658</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>56.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.69818</td>\n",
       "      <td>-1.579244</td>\n",
       "      <td>-0.513953</td>\n",
       "      <td>26.170573</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>386</td>\n",
       "      <td>62</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.2000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>68.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53200</td>\n",
       "      <td>-2.900000</td>\n",
       "      <td>-1.900000</td>\n",
       "      <td>26.170573</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>387</td>\n",
       "      <td>66</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>236.983784</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.505219</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>47.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62600</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>26.170573</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Age  Tscore_Hip_total   CRP      Cr         ALP        BUN  \\\n",
       "0             0   63         -0.200000   5.0  1.0000   90.000000  16.000000   \n",
       "1             1   69         -0.500000   9.0  1.0384  236.983784  17.019137   \n",
       "2             2   60          1.100000  10.0  0.8000  142.000000  17.000000   \n",
       "3             3   59         -0.400000  14.0  0.7000  202.000000  17.000000   \n",
       "4             4   50          1.500000   1.0  1.2000  146.000000  14.000000   \n",
       "..          ...  ...               ...   ...     ...         ...        ...   \n",
       "383         383   58          0.000000   3.0  3.0000  246.000000  28.000000   \n",
       "384         384   59         -0.543658   5.0  0.8000  141.000000  14.000000   \n",
       "385         385   64         -0.543658   6.0  0.9000  143.000000  14.000000   \n",
       "386         386   62         -3.000000  10.0  1.2000  202.000000  17.000000   \n",
       "387         387   66         -4.000000   2.0  0.9000  236.983784  22.000000   \n",
       "\n",
       "            P        Ca    PTH  ...  BMD_Hip_Neck  Tscore_Hip_neck  \\\n",
       "0    4.000000  8.400000  28.80  ...       0.75200        -1.500000   \n",
       "1    3.505219  8.627989  50.85  ...       0.73400        -1.400000   \n",
       "2    3.700000  8.600000  15.50  ...       0.68900        -1.800000   \n",
       "3    4.200000  7.900000  50.85  ...       0.65400        -2.000000   \n",
       "4    3.000000  8.800000  66.00  ...       1.02700         0.700000   \n",
       "..        ...       ...    ...  ...           ...              ...   \n",
       "383  4.100000  8.500000  35.00  ...       0.72300        -1.100000   \n",
       "384  3.800000  8.600000  35.00  ...       0.69818        -1.579244   \n",
       "385  4.500000  8.500000  56.00  ...       0.69818        -1.579244   \n",
       "386  4.500000  8.300000  68.00  ...       0.53200        -2.900000   \n",
       "387  3.505219  8.500000  47.20  ...       0.62600        -2.000000   \n",
       "\n",
       "     Zscore_Hip_neck        BMI  Histroy_Anticoagulant  Active_Smoking  \\\n",
       "0           0.500000  40.800000                      0               0   \n",
       "1          -0.300000  40.000000                      0               0   \n",
       "2          -0.800000  38.200000                      0               1   \n",
       "3          -1.100000  38.100000                      1               1   \n",
       "4           1.500000  36.100000                      0               0   \n",
       "..               ...        ...                    ...             ...   \n",
       "383         0.000000  24.400000                      0               0   \n",
       "384        -0.513953  26.170573                      1               0   \n",
       "385        -0.513953  26.170573                      0               0   \n",
       "386        -1.900000  26.170573                      0               0   \n",
       "387        -0.500000  26.170573                      1               0   \n",
       "\n",
       "     History_Smoking  Calcium_Supplement  History_Diabetes_2  Refracture  \n",
       "0                  0                   0                   0           0  \n",
       "1                  0                   0                   0           1  \n",
       "2                  1                   0                   0           0  \n",
       "3                  1                   0                   1           1  \n",
       "4                  0                   0                   0           0  \n",
       "..               ...                 ...                 ...         ...  \n",
       "383                0                   0                   0           0  \n",
       "384                0                   0                   0           0  \n",
       "385                0                   0                   0           0  \n",
       "386                0                   0                   0           1  \n",
       "387                0                   0                   0           0  \n",
       "\n",
       "[388 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dataset = pd.read_csv(\"Dataset_male_Final.csv\")\n",
    "display(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdfe2929",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.drop(\"Unnamed: 0\", axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37848cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Tscore_Hip_total</th>\n",
       "      <th>CRP</th>\n",
       "      <th>Cr</th>\n",
       "      <th>ALP</th>\n",
       "      <th>BUN</th>\n",
       "      <th>P</th>\n",
       "      <th>Ca</th>\n",
       "      <th>PTH</th>\n",
       "      <th>Vit_D3</th>\n",
       "      <th>...</th>\n",
       "      <th>BMD_Hip_Neck</th>\n",
       "      <th>Tscore_Hip_neck</th>\n",
       "      <th>Zscore_Hip_neck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Histroy_Anticoagulant</th>\n",
       "      <th>Active_Smoking</th>\n",
       "      <th>History_Smoking</th>\n",
       "      <th>Calcium_Supplement</th>\n",
       "      <th>History_Diabetes_2</th>\n",
       "      <th>Refracture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>28.80</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75200</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>40.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0384</td>\n",
       "      <td>236.983784</td>\n",
       "      <td>17.019137</td>\n",
       "      <td>3.505219</td>\n",
       "      <td>8.627989</td>\n",
       "      <td>50.85</td>\n",
       "      <td>33.313143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.73400</td>\n",
       "      <td>-1.400000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>15.50</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.68900</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>38.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>50.85</td>\n",
       "      <td>33.313143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65400</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>38.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>66.00</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.02700</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>36.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>58</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>35.00</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72300</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>59</td>\n",
       "      <td>-0.543658</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>35.00</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.69818</td>\n",
       "      <td>-1.579244</td>\n",
       "      <td>-0.513953</td>\n",
       "      <td>26.170573</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>64</td>\n",
       "      <td>-0.543658</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>56.00</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.69818</td>\n",
       "      <td>-1.579244</td>\n",
       "      <td>-0.513953</td>\n",
       "      <td>26.170573</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>62</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.2000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>68.00</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53200</td>\n",
       "      <td>-2.900000</td>\n",
       "      <td>-1.900000</td>\n",
       "      <td>26.170573</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>66</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>236.983784</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.505219</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>47.20</td>\n",
       "      <td>33.313143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62600</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>26.170573</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Tscore_Hip_total   CRP      Cr         ALP        BUN         P  \\\n",
       "0     63         -0.200000   5.0  1.0000   90.000000  16.000000  4.000000   \n",
       "1     69         -0.500000   9.0  1.0384  236.983784  17.019137  3.505219   \n",
       "2     60          1.100000  10.0  0.8000  142.000000  17.000000  3.700000   \n",
       "3     59         -0.400000  14.0  0.7000  202.000000  17.000000  4.200000   \n",
       "4     50          1.500000   1.0  1.2000  146.000000  14.000000  3.000000   \n",
       "..   ...               ...   ...     ...         ...        ...       ...   \n",
       "383   58          0.000000   3.0  3.0000  246.000000  28.000000  4.100000   \n",
       "384   59         -0.543658   5.0  0.8000  141.000000  14.000000  3.800000   \n",
       "385   64         -0.543658   6.0  0.9000  143.000000  14.000000  4.500000   \n",
       "386   62         -3.000000  10.0  1.2000  202.000000  17.000000  4.500000   \n",
       "387   66         -4.000000   2.0  0.9000  236.983784  22.000000  3.505219   \n",
       "\n",
       "           Ca    PTH     Vit_D3  ...  BMD_Hip_Neck  Tscore_Hip_neck  \\\n",
       "0    8.400000  28.80  19.900000  ...       0.75200        -1.500000   \n",
       "1    8.627989  50.85  33.313143  ...       0.73400        -1.400000   \n",
       "2    8.600000  15.50  25.000000  ...       0.68900        -1.800000   \n",
       "3    7.900000  50.85  33.313143  ...       0.65400        -2.000000   \n",
       "4    8.800000  66.00  38.000000  ...       1.02700         0.700000   \n",
       "..        ...    ...        ...  ...           ...              ...   \n",
       "383  8.500000  35.00  33.000000  ...       0.72300        -1.100000   \n",
       "384  8.600000  35.00  32.000000  ...       0.69818        -1.579244   \n",
       "385  8.500000  56.00  38.000000  ...       0.69818        -1.579244   \n",
       "386  8.300000  68.00  29.000000  ...       0.53200        -2.900000   \n",
       "387  8.500000  47.20  33.313143  ...       0.62600        -2.000000   \n",
       "\n",
       "     Zscore_Hip_neck        BMI  Histroy_Anticoagulant  Active_Smoking  \\\n",
       "0           0.500000  40.800000                      0               0   \n",
       "1          -0.300000  40.000000                      0               0   \n",
       "2          -0.800000  38.200000                      0               1   \n",
       "3          -1.100000  38.100000                      1               1   \n",
       "4           1.500000  36.100000                      0               0   \n",
       "..               ...        ...                    ...             ...   \n",
       "383         0.000000  24.400000                      0               0   \n",
       "384        -0.513953  26.170573                      1               0   \n",
       "385        -0.513953  26.170573                      0               0   \n",
       "386        -1.900000  26.170573                      0               0   \n",
       "387        -0.500000  26.170573                      1               0   \n",
       "\n",
       "     History_Smoking  Calcium_Supplement  History_Diabetes_2  Refracture  \n",
       "0                  0                   0                   0           0  \n",
       "1                  0                   0                   0           1  \n",
       "2                  1                   0                   0           0  \n",
       "3                  1                   0                   1           1  \n",
       "4                  0                   0                   0           0  \n",
       "..               ...                 ...                 ...         ...  \n",
       "383                0                   0                   0           0  \n",
       "384                0                   0                   0           0  \n",
       "385                0                   0                   0           0  \n",
       "386                0                   0                   0           1  \n",
       "387                0                   0                   0           0  \n",
       "\n",
       "[388 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32dbe64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Tscore_Hip_total', 'CRP', 'Cr', 'ALP', 'BUN', 'P', 'Ca', 'PTH',\n",
       "       'Vit_D3', 'BMD_vertebra', 'Tscore_vertebra', 'Zscore_vertebra',\n",
       "       'BMD_Hip_total', 'Zscore_hip_total', 'BMD_Hip_Neck', 'Tscore_Hip_neck',\n",
       "       'Zscore_Hip_neck', 'BMI', 'Histroy_Anticoagulant', 'Active_Smoking',\n",
       "       'History_Smoking', 'Calcium_Supplement', 'History_Diabetes_2',\n",
       "       'Refracture'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37d7f1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Column Identified outliers: 1\n",
      "Age Column Identified outliers: 0\n",
      "Tscore_Hip_total Column Identified outliers: 3\n",
      "Tscore_Hip_total Column Identified outliers: 0\n",
      "CRP Column Identified outliers: 15\n",
      "CRP Column Identified outliers: 0\n",
      "Cr Column Identified outliers: 6\n",
      "Cr Column Identified outliers: 0\n",
      "ALP Column Identified outliers: 1\n",
      "ALP Column Identified outliers: 0\n",
      "BUN Column Identified outliers: 4\n",
      "BUN Column Identified outliers: 0\n",
      "P Column Identified outliers: 4\n",
      "P Column Identified outliers: 0\n",
      "Ca Column Identified outliers: 4\n",
      "Ca Column Identified outliers: 0\n",
      "PTH Column Identified outliers: 2\n",
      "PTH Column Identified outliers: 0\n",
      "Vit_D3 Column Identified outliers: 5\n",
      "Vit_D3 Column Identified outliers: 0\n",
      "BMD_vertebra Column Identified outliers: 3\n",
      "BMD_vertebra Column Identified outliers: 0\n",
      "Tscore_vertebra Column Identified outliers: 3\n",
      "Tscore_vertebra Column Identified outliers: 0\n",
      "Zscore_vertebra Column Identified outliers: 2\n",
      "Zscore_vertebra Column Identified outliers: 0\n",
      "BMD_Hip_total Column Identified outliers: 3\n",
      "BMD_Hip_total Column Identified outliers: 0\n",
      "Zscore_hip_total Column Identified outliers: 2\n",
      "Zscore_hip_total Column Identified outliers: 0\n",
      "BMD_Hip_Neck Column Identified outliers: 2\n",
      "BMD_Hip_Neck Column Identified outliers: 0\n",
      "Tscore_Hip_neck Column Identified outliers: 3\n",
      "Tscore_Hip_neck Column Identified outliers: 0\n",
      "Zscore_Hip_neck Column Identified outliers: 3\n",
      "Zscore_Hip_neck Column Identified outliers: 0\n",
      "BMI Column Identified outliers: 2\n",
      "BMI Column Identified outliers: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Age'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Tscore_Hip_total'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Tscore_Hip_total'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['CRP'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Cr'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Cr'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['ALP'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['BUN'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['P'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['P'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Ca'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Ca'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:173: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['PTH'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:193: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Vit_D3'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['BMD_vertebra'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['BMD_vertebra'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:233: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Tscore_vertebra'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:253: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Zscore_vertebra'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:268: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['BMD_Hip_total'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['BMD_Hip_total'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:293: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Zscore_hip_total'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:313: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['BMD_Hip_Neck'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:333: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Tscore_Hip_neck'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:353: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Zscore_Hip_neck'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_5348\\1247371120.py:374: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['BMI'][i] = upper\n"
     ]
    }
   ],
   "source": [
    "data_mean, data_std = np.mean(Dataset['Age']), np.std(Dataset['Age'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Age'] if x < lower or x > upper]\n",
    "print('Age Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Age'])):\n",
    "    if Dataset['Age'][i] < lower:\n",
    "        Dataset['Age'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Age'])):\n",
    "    if Dataset['Age'][i] > upper:\n",
    "        Dataset['Age'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Age'] if x < lower or x > upper]\n",
    "print('Age Column Identified outliers: %d' % len(outliers))\n",
    "###########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Tscore_Hip_total']), np.std(Dataset['Tscore_Hip_total'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Tscore_Hip_total'] if x < lower or x > upper]\n",
    "print('Tscore_Hip_total Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Tscore_Hip_total'])):\n",
    "    if Dataset['Tscore_Hip_total'][i] < lower:\n",
    "        Dataset['Tscore_Hip_total'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Tscore_Hip_total'])):\n",
    "    if Dataset['Tscore_Hip_total'][i] > upper:\n",
    "        Dataset['Tscore_Hip_total'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Tscore_Hip_total'] if x < lower or x > upper]\n",
    "print('Tscore_Hip_total Column Identified outliers: %d' % len(outliers))\n",
    "#########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['CRP']), np.std(Dataset['CRP'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['CRP'] if x < lower or x > upper]\n",
    "print('CRP Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['CRP'])):\n",
    "    if Dataset['CRP'][i] < lower:\n",
    "        Dataset['CRP'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['CRP'])):\n",
    "    if Dataset['CRP'][i] > upper:\n",
    "        Dataset['CRP'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['CRP'] if x < lower or x > upper]\n",
    "print('CRP Column Identified outliers: %d' % len(outliers))\n",
    "########################################################################################\n",
    "data_mean, data_std = np.mean(Dataset['Cr']), np.std(Dataset['Cr'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Cr'] if x < lower or x > upper]\n",
    "print('Cr Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Cr'])):\n",
    "    if Dataset['Cr'][i] < lower:\n",
    "        Dataset['Cr'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Cr'])):\n",
    "    if Dataset['Cr'][i] > upper:\n",
    "        Dataset['Cr'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Cr'] if x < lower or x > upper]\n",
    "print('Cr Column Identified outliers: %d' % len(outliers))\n",
    "###########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['ALP']), np.std(Dataset['ALP'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['ALP'] if x < lower or x > upper]\n",
    "print('ALP Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['ALP'])):\n",
    "    if Dataset['ALP'][i] < lower:\n",
    "        Dataset['ALP'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['ALP'])):\n",
    "    if Dataset['ALP'][i] > upper:\n",
    "        Dataset['ALP'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['ALP'] if x < lower or x > upper]\n",
    "print('ALP Column Identified outliers: %d' % len(outliers))\n",
    "##########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['BUN']), np.std(Dataset['BUN'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['BUN'] if x < lower or x > upper]\n",
    "print('BUN Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['BUN'])):\n",
    "    if Dataset['BUN'][i] < lower:\n",
    "        Dataset['BUN'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['BUN'])):\n",
    "    if Dataset['BUN'][i] > upper:\n",
    "        Dataset['BUN'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['BUN'] if x < lower or x > upper]\n",
    "print('BUN Column Identified outliers: %d' % len(outliers))\n",
    "#############################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['P']), np.std(Dataset['P'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['P'] if x < lower or x > upper]\n",
    "print('P Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['P'])):\n",
    "    if Dataset['P'][i] < lower:\n",
    "        Dataset['P'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['P'])):\n",
    "    if Dataset['P'][i] > upper:\n",
    "        Dataset['P'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['P'] if x < lower or x > upper]\n",
    "print('P Column Identified outliers: %d' % len(outliers))\n",
    "##############################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Ca']), np.std(Dataset['Ca'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Ca'] if x < lower or x > upper]\n",
    "print('Ca Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Ca'])):\n",
    "    if Dataset['Ca'][i] < lower:\n",
    "        Dataset['Ca'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Ca'])):\n",
    "    if Dataset['Ca'][i] > upper:\n",
    "        Dataset['Ca'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Ca'] if x < lower or x > upper]\n",
    "print('Ca Column Identified outliers: %d' % len(outliers))\n",
    "############################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['PTH']), np.std(Dataset['PTH'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['PTH'] if x < lower or x > upper]\n",
    "print('PTH Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['PTH'])):\n",
    "    if Dataset['PTH'][i] < lower:\n",
    "        Dataset['PTH'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['PTH'])):\n",
    "    if Dataset['PTH'][i] > upper:\n",
    "        Dataset['PTH'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['PTH'] if x < lower or x > upper]\n",
    "print('PTH Column Identified outliers: %d' % len(outliers))\n",
    "##########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Vit_D3']), np.std(Dataset['Vit_D3'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Vit_D3'] if x < lower or x > upper]\n",
    "print('Vit_D3 Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Vit_D3'])):\n",
    "    if Dataset['Vit_D3'][i] < lower:\n",
    "        Dataset['Vit_D3'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Vit_D3'])):\n",
    "    if Dataset['Vit_D3'][i] > upper:\n",
    "        Dataset['Vit_D3'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Vit_D3'] if x < lower or x > upper]\n",
    "print('Vit_D3 Column Identified outliers: %d' % len(outliers))\n",
    "########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['BMD_vertebra']), np.std(Dataset['BMD_vertebra'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['BMD_vertebra'] if x < lower or x > upper]\n",
    "print('BMD_vertebra Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['BMD_vertebra'])):\n",
    "    if Dataset['BMD_vertebra'][i] < lower:\n",
    "        Dataset['BMD_vertebra'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['BMD_vertebra'])):\n",
    "    if Dataset['BMD_vertebra'][i] > upper:\n",
    "        Dataset['BMD_vertebra'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['BMD_vertebra'] if x < lower or x > upper]\n",
    "print('BMD_vertebra Column Identified outliers: %d' % len(outliers))\n",
    "############################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Tscore_vertebra']), np.std(Dataset['Tscore_vertebra'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Tscore_vertebra'] if x < lower or x > upper]\n",
    "print('Tscore_vertebra Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Tscore_vertebra'])):\n",
    "    if Dataset['Tscore_vertebra'][i] < lower:\n",
    "        Dataset['Tscore_vertebra'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Tscore_vertebra'])):\n",
    "    if Dataset['Tscore_vertebra'][i] > upper:\n",
    "        Dataset['Tscore_vertebra'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Tscore_vertebra'] if x < lower or x > upper]\n",
    "print('Tscore_vertebra Column Identified outliers: %d' % len(outliers))\n",
    "##########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Zscore_vertebra']), np.std(Dataset['Zscore_vertebra'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Zscore_vertebra'] if x < lower or x > upper]\n",
    "print('Zscore_vertebra Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Zscore_vertebra'])):\n",
    "    if Dataset['Zscore_vertebra'][i] < lower:\n",
    "        Dataset['Zscore_vertebra'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Zscore_vertebra'])):\n",
    "    if Dataset['Zscore_vertebra'][i] > upper:\n",
    "        Dataset['Zscore_vertebra'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Zscore_vertebra'] if x < lower or x > upper]\n",
    "print('Zscore_vertebra Column Identified outliers: %d' % len(outliers))\n",
    "########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['BMD_Hip_total']), np.std(Dataset['BMD_Hip_total'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['BMD_Hip_total'] if x < lower or x > upper]\n",
    "print('BMD_Hip_total Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['BMD_Hip_total'])):\n",
    "    if Dataset['BMD_Hip_total'][i] < lower:\n",
    "        Dataset['BMD_Hip_total'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['BMD_Hip_total'])):\n",
    "    if Dataset['BMD_Hip_total'][i] > upper:\n",
    "        Dataset['BMD_Hip_total'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['BMD_Hip_total'] if x < lower or x > upper]\n",
    "print('BMD_Hip_total Column Identified outliers: %d' % len(outliers))\n",
    "############################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Zscore_hip_total']), np.std(Dataset['Zscore_hip_total'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Zscore_hip_total'] if x < lower or x > upper]\n",
    "print('Zscore_hip_total Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Zscore_hip_total'])):\n",
    "    if Dataset['Zscore_hip_total'][i] < lower:\n",
    "        Dataset['Zscore_hip_total'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Zscore_hip_total'])):\n",
    "    if Dataset['Zscore_hip_total'][i] > upper:\n",
    "        Dataset['Zscore_hip_total'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Zscore_hip_total'] if x < lower or x > upper]\n",
    "print('Zscore_hip_total Column Identified outliers: %d' % len(outliers))\n",
    "##########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['BMD_Hip_Neck']), np.std(Dataset['BMD_Hip_Neck'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['BMD_Hip_Neck'] if x < lower or x > upper]\n",
    "print('BMD_Hip_Neck Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['BMD_Hip_Neck'])):\n",
    "    if Dataset['BMD_Hip_Neck'][i] < lower:\n",
    "        Dataset['BMD_Hip_Neck'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['BMD_Hip_Neck'])):\n",
    "    if Dataset['BMD_Hip_Neck'][i] > upper:\n",
    "        Dataset['BMD_Hip_Neck'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['BMD_Hip_Neck'] if x < lower or x > upper]\n",
    "print('BMD_Hip_Neck Column Identified outliers: %d' % len(outliers))\n",
    "########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Tscore_Hip_neck']), np.std(Dataset['Tscore_Hip_neck'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Tscore_Hip_neck'] if x < lower or x > upper]\n",
    "print('Tscore_Hip_neck Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Tscore_Hip_neck'])):\n",
    "    if Dataset['Tscore_Hip_neck'][i] < lower:\n",
    "        Dataset['Tscore_Hip_neck'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Tscore_Hip_neck'])):\n",
    "    if Dataset['Tscore_Hip_neck'][i] > upper:\n",
    "        Dataset['Tscore_Hip_neck'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Tscore_Hip_neck'] if x < lower or x > upper]\n",
    "print('Tscore_Hip_neck Column Identified outliers: %d' % len(outliers))\n",
    "############################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Zscore_Hip_neck']), np.std(Dataset['Zscore_Hip_neck'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Zscore_Hip_neck'] if x < lower or x > upper]\n",
    "print('Zscore_Hip_neck Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Zscore_Hip_neck'])):\n",
    "    if Dataset['Zscore_Hip_neck'][i] < lower:\n",
    "        Dataset['Zscore_Hip_neck'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Zscore_Hip_neck'])):\n",
    "    if Dataset['Zscore_Hip_neck'][i] > upper:\n",
    "        Dataset['Zscore_Hip_neck'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Zscore_Hip_neck'] if x < lower or x > upper]\n",
    "print('Zscore_Hip_neck Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['BMI']), np.std(Dataset['BMI'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['BMI'] if x < lower or x > upper]\n",
    "print('BMI Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['BMI'])):\n",
    "    if Dataset['BMI'][i] < lower:\n",
    "        Dataset['BMI'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['BMI'])):\n",
    "    if Dataset['BMI'][i] > upper:\n",
    "        Dataset['BMI'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['BMI'] if x < lower or x > upper]\n",
    "print('BMI Column Identified outliers: %d' % len(outliers))\n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08c2cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= Dataset.loc[:, Dataset.columns != 'Refracture']\n",
    "Y = Dataset[\"Refracture\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a44f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=5)\n",
    "X_balanced, Y_balanced = sm.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df709cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Tscore_Hip_total', 'CRP', 'Cr', 'ALP', 'BUN', 'P', 'Ca', 'PTH',\n",
       "       'Vit_D3', 'BMD_vertebra', 'Tscore_vertebra', 'Zscore_vertebra',\n",
       "       'BMD_Hip_total', 'Zscore_hip_total', 'BMD_Hip_Neck', 'Tscore_Hip_neck',\n",
       "       'Zscore_Hip_neck', 'BMI', 'Histroy_Anticoagulant', 'Active_Smoking',\n",
       "       'History_Smoking', 'Calcium_Supplement', 'History_Diabetes_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dae51c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Tscore_Hip_total</th>\n",
       "      <th>CRP</th>\n",
       "      <th>Cr</th>\n",
       "      <th>ALP</th>\n",
       "      <th>BUN</th>\n",
       "      <th>P</th>\n",
       "      <th>Ca</th>\n",
       "      <th>PTH</th>\n",
       "      <th>Vit_D3</th>\n",
       "      <th>...</th>\n",
       "      <th>Zscore_hip_total</th>\n",
       "      <th>BMD_Hip_Neck</th>\n",
       "      <th>Tscore_Hip_neck</th>\n",
       "      <th>Zscore_Hip_neck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Histroy_Anticoagulant</th>\n",
       "      <th>Active_Smoking</th>\n",
       "      <th>History_Smoking</th>\n",
       "      <th>Calcium_Supplement</th>\n",
       "      <th>History_Diabetes_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.512182</td>\n",
       "      <td>-0.001626</td>\n",
       "      <td>0.040649</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.731689</td>\n",
       "      <td>0.130078</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>0.068291</td>\n",
       "      <td>0.234141</td>\n",
       "      <td>0.161785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.310667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.267484</td>\n",
       "      <td>-0.001938</td>\n",
       "      <td>0.034889</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.918686</td>\n",
       "      <td>0.065976</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>0.033447</td>\n",
       "      <td>0.197124</td>\n",
       "      <td>0.129141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>-0.005427</td>\n",
       "      <td>-0.001163</td>\n",
       "      <td>0.148136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.368022</td>\n",
       "      <td>0.006747</td>\n",
       "      <td>0.061337</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.870985</td>\n",
       "      <td>0.104273</td>\n",
       "      <td>0.022695</td>\n",
       "      <td>0.052750</td>\n",
       "      <td>0.095072</td>\n",
       "      <td>0.153343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011041</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>-0.011041</td>\n",
       "      <td>-0.004907</td>\n",
       "      <td>0.234307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.263828</td>\n",
       "      <td>-0.001789</td>\n",
       "      <td>0.062603</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>0.903275</td>\n",
       "      <td>0.076018</td>\n",
       "      <td>0.018781</td>\n",
       "      <td>0.035326</td>\n",
       "      <td>0.227384</td>\n",
       "      <td>0.148965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>-0.008943</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>0.170370</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.282948</td>\n",
       "      <td>0.008488</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>0.826207</td>\n",
       "      <td>0.079225</td>\n",
       "      <td>0.016977</td>\n",
       "      <td>0.049799</td>\n",
       "      <td>0.373491</td>\n",
       "      <td>0.215040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010752</td>\n",
       "      <td>0.005812</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>0.008488</td>\n",
       "      <td>0.204288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Tscore_Hip_total       CRP        Cr       ALP       BUN  \\\n",
       "0  0.512182         -0.001626  0.040649  0.008130  0.731689  0.130078   \n",
       "1  0.267484         -0.001938  0.034889  0.004025  0.918686  0.065976   \n",
       "2  0.368022          0.006747  0.061337  0.004907  0.870985  0.104273   \n",
       "3  0.263828         -0.001789  0.062603  0.003130  0.903275  0.076018   \n",
       "4  0.282948          0.008488  0.005659  0.006791  0.826207  0.079225   \n",
       "\n",
       "          P        Ca       PTH    Vit_D3  ...  Zscore_hip_total  \\\n",
       "0  0.032520  0.068291  0.234141  0.161785  ...          0.002439   \n",
       "1  0.013588  0.033447  0.197124  0.129141  ...          0.000388   \n",
       "2  0.022695  0.052750  0.095072  0.153343  ...          0.011041   \n",
       "3  0.018781  0.035326  0.227384  0.148965  ...          0.000000   \n",
       "4  0.016977  0.049799  0.373491  0.215040  ...          0.010752   \n",
       "\n",
       "   BMD_Hip_Neck  Tscore_Hip_neck  Zscore_Hip_neck       BMI  \\\n",
       "0      0.006114        -0.012195         0.004065  0.310667   \n",
       "1      0.002845        -0.005427        -0.001163  0.148136   \n",
       "2      0.004226        -0.011041        -0.004907  0.234307   \n",
       "3      0.002924        -0.008943        -0.004919  0.170370   \n",
       "4      0.005812         0.003961         0.008488  0.204288   \n",
       "\n",
       "   Histroy_Anticoagulant  Active_Smoking  History_Smoking  Calcium_Supplement  \\\n",
       "0                      0               0                0                   0   \n",
       "1                      0               0                0                   0   \n",
       "2                      0               1                1                   0   \n",
       "3                      1               1                1                   0   \n",
       "4                      0               0                0                   0   \n",
       "\n",
       "   History_Diabetes_2  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   1  \n",
       "4                   0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_balanced[['Age', 'Tscore_Hip_total','CRP',\n",
    "       'Cr', 'ALP', 'BUN',\n",
    "       'P', 'Ca', 'PTH'\n",
    "       ,'Vit_D3', 'BMD_vertebra', 'Tscore_vertebra', 'Zscore_vertebra',\n",
    "        'BMD_Hip_total', 'Zscore_hip_total', 'BMD_Hip_Neck', 'Tscore_Hip_neck',\n",
    "        'Zscore_Hip_neck', 'BMI']] = normalize(X_balanced[['Age', 'Tscore_Hip_total','CRP',\n",
    "       'Cr', 'ALP', 'BUN',\n",
    "       'P', 'Ca', 'PTH'\n",
    "       ,'Vit_D3', 'BMD_vertebra', 'Tscore_vertebra', 'Zscore_vertebra',\n",
    "        'BMD_Hip_total', 'Zscore_hip_total', 'BMD_Hip_Neck', 'Tscore_Hip_neck',\n",
    "        'Zscore_Hip_neck', 'BMI']])\n",
    "X_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2904a281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Tscore_Hip_total', 'CRP', 'Cr', 'ALP', 'BUN', 'P', 'Ca', 'PTH',\n",
       "       'Vit_D3', 'BMD_vertebra', 'Tscore_vertebra', 'Zscore_vertebra',\n",
       "       'BMD_Hip_total', 'Zscore_hip_total', 'BMD_Hip_Neck', 'Tscore_Hip_neck',\n",
       "       'Zscore_Hip_neck', 'BMI', 'Histroy_Anticoagulant', 'Active_Smoking',\n",
       "       'History_Smoking', 'Calcium_Supplement', 'History_Diabetes_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Y_balanced\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04891e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(results):\n",
    "    print(f'Best parameters are: {results.best_params_}')\n",
    "    print(f'Best Score is : {results.best_score_} ')\n",
    "    print(\"\\n\")\n",
    "    mean_score = results.cv_results_['mean_test_score']\n",
    "    std_score = results.cv_results_['std_test_score']\n",
    "    params = results.cv_results_['params']\n",
    "    for mean,std,params in zip(mean_score,std_score,params):\n",
    "        print(f'{round(mean,3)} + or -{round(std,3)} for the {params}')\n",
    "        \n",
    "def showResults(model, modelType , X, Y):\n",
    "    scores_accuracy = cross_val_score(model, X, Y, cv=10, scoring='accuracy')\n",
    "    scores_log_loss = cross_val_score(model, X, Y, cv=10, scoring='neg_log_loss')\n",
    "    scores_briar = cross_val_score(model, X, Y, cv=10, scoring='neg_brier_score')\n",
    "    scores_auc = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\n",
    "    scores_recall = cross_val_score(model, X, Y, cv=10, scoring='recall')\n",
    "    scores_precision = cross_val_score(model, X, Y, cv=10, scoring='precision')\n",
    "    scores_f1 = cross_val_score(model, X, Y, cv=10, scoring='f1')\n",
    "    print('K-fold cross-validation results:')\n",
    "    print(modelType ,\" average accuracy is %2.3f\" % scores_accuracy.mean())\n",
    "    print(modelType ,\" average log_loss is %2.3f\" % -scores_log_loss.mean())\n",
    "    print(modelType ,\" average brier score is %2.3f\" % -scores_briar.mean())\n",
    "    print(modelType ,\" average auc is %2.3f\" % scores_auc.mean())\n",
    "    print(modelType ,\" average recall is %2.3f\" % scores_recall.mean())\n",
    "    print(modelType ,\" average precision is %2.3f\" % scores_precision.mean())\n",
    "    print(modelType ,\" average f1 is %2.3f\" % scores_f1.mean())\n",
    "    \n",
    "params = {\n",
    "    \"max_depth\": [ 3, 4, 6, 8, 10, 15],\n",
    "    'n_estimators': range(100,1000,200),\n",
    "    'learning_rate': [0.1,0.01,0.001],\n",
    "    \"colsample_bytree\" : [0.3, 0.5 , 0.8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c53a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pysician Opinion\n",
    "X = X_balanced[['Age', 'Tscore_Hip_total', 'CRP', 'Cr', 'ALP', 'BUN', 'P', 'Ca', 'PTH',\n",
    "       'Vit_D3', 'BMD_vertebra', 'Tscore_vertebra', 'Zscore_vertebra',\n",
    "       'BMD_Hip_total', 'Zscore_hip_total', 'BMD_Hip_Neck', 'Tscore_Hip_neck',\n",
    "       'Zscore_Hip_neck', 'BMI', 'Histroy_Anticoagulant', 'Active_Smoking',\n",
    "       'History_Smoking', 'Calcium_Supplement', 'History_Diabetes_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92fad6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 270 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_c...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.3, 0.5, 0.8],\n",
       "                         'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': [3, 4, 6, 8, 10, 15],\n",
       "                         'n_estimators': range(100, 1000, 200)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "cv = GridSearchCV(xgb,params,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "723db357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "Best Score is : 0.9196930946291559 \n",
      "\n",
      "\n",
      "0.829 + or -0.069 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.87 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.886 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.883 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.892 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.864 + or -0.069 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.904 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.907 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.907 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.909 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.883 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.898 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.904 + or -0.042 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.904 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.901 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.893 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.904 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.905 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.904 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.905 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.901 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.902 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.902 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.896 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.898 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.895 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.909 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.899 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.904 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.904 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.794 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.808 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.817 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.823 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.83 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.822 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.838 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.839 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.85 + or -0.077 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.852 + or -0.071 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.854 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.87 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.882 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.892 + or -0.067 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.898 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.886 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.901 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.911 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.911 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.912 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.901 + or -0.042 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.912 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.917 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.917 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.918 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.915 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.917 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.915 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.918 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.92 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.784 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.788 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.794 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.795 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.795 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.806 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.822 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.823 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.83 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.83 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.842 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.847 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.854 + or -0.042 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.855 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.855 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.87 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.886 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.889 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.889 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.888 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.893 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.901 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.902 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.904 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.907 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.907 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.904 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.905 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.911 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.911 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.832 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.885 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.892 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.898 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.895 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.866 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.893 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.895 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.895 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.896 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.876 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.889 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.89 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.896 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.896 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.89 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.898 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.899 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.895 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.896 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.898 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.902 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.905 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.901 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.899 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.898 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.907 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.902 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.901 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.907 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.775 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.795 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.814 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.828 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.828 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.814 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.816 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.836 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.851 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.858 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.857 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.845 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.863 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.873 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.882 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.88 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.873 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.879 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.895 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.899 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.885 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.891 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.889 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.901 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.901 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.888 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.896 + or -0.065 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.898 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.899 + or -0.065 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.898 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.766 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.771 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.778 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.779 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.778 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.804 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.809 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.812 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.817 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.817 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.855 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.851 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.851 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.851 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.854 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.873 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.872 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.87 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.872 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.876 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.894 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.882 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.885 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.882 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.883 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.895 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.888 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.888 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.891 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.898 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.838 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.871 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.892 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.896 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.896 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.868 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.896 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.901 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.902 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.898 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.882 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.901 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.895 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.896 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.898 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.886 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.893 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.896 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.899 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.896 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.883 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.892 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.893 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.895 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.896 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.871 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.886 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.888 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.887 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.889 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.754 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.8 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.812 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.826 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.835 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.791 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.811 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.838 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.848 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.851 + or -0.082 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.814 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.838 + or -0.094 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.851 + or -0.085 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.876 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.888 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.833 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.842 + or -0.094 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.848 + or -0.095 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.867 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.876 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.833 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.842 + or -0.091 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.861 + or -0.093 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.868 + or -0.082 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.883 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.847 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.852 + or -0.091 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.861 + or -0.092 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.873 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.883 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.718 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.718 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.724 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.735 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.752 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.772 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.772 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.775 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.792 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.797 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.809 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.813 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.817 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.819 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.816 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.82 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.82 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.829 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.833 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.831 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.825 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.826 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.832 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.839 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.839 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.829 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.828 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.842 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.844 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.847 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82fac922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "XGBoost  average accuracy is 0.920\n",
      "XGBoost  average log_loss is 0.234\n",
      "XGBoost  average brier score is 0.066\n",
      "XGBoost  average auc is 0.973\n",
      "XGBoost  average recall is 0.953\n",
      "XGBoost  average precision is 0.893\n",
      "XGBoost  average f1 is 0.921\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42, n_estimators=900,\n",
    "                   max_depth = 15, learning_rate = 0.01, colsample_bytree = 0.3)\n",
    "xgb.fit(X,Y)\n",
    "\n",
    "showResults(xgb, \"XGBoost\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0319961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV + Random Forest\n",
    "X = X_balanced[['Age', 'Tscore_Hip_total', 'CRP', 'Cr', 'ALP', 'BUN', 'Ca', 'PTH', \n",
    "       'Vit_D3', 'Zscore_vertebra', 'BMD_Hip_total', 'Tscore_Hip_neck']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a72f5e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 270 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_c...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.3, 0.5, 0.8],\n",
       "                         'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': [3, 4, 6, 8, 10, 15],\n",
       "                         'n_estimators': range(100, 1000, 200)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "cv = GridSearchCV(xgb,params,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a168b555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "Best Score is : 0.9225916453537936 \n",
      "\n",
      "\n",
      "0.829 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.857 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.87 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.874 + or -0.035 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.871 + or -0.034 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.86 + or -0.035 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.892 + or -0.03 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.895 + or -0.029 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.89 + or -0.031 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.89 + or -0.034 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.896 + or -0.034 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.907 + or -0.033 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.904 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.902 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.902 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.905 + or -0.033 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.912 + or -0.032 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.915 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.914 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.909 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.908 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.901 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.907 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.906 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.905 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.911 + or -0.042 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.909 + or -0.032 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.911 + or -0.04 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.911 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.911 + or -0.032 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.75 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.778 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.801 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.812 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.817 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.787 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.809 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.832 + or -0.032 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.844 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.86 + or -0.033 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.85 + or -0.035 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.882 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.892 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.899 + or -0.033 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.905 + or -0.034 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.882 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.898 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.904 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.906 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.912 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.905 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.909 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.914 + or -0.04 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.915 + or -0.042 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.912 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.905 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.92 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.921 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.923 + or -0.042 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.918 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.751 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.756 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.762 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.75 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.752 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.779 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.782 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.785 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.788 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.791 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.838 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.842 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.845 + or -0.04 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.855 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.86 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.874 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.883 + or -0.033 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.879 + or -0.031 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.889 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.889 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.888 + or -0.042 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.893 + or -0.029 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.902 + or -0.032 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.899 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.905 + or -0.035 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.89 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.898 + or -0.029 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.904 + or -0.034 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.908 + or -0.034 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.908 + or -0.035 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.85 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.873 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.886 + or -0.032 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.892 + or -0.031 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.889 + or -0.033 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.88 + or -0.036 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.899 + or -0.028 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.899 + or -0.031 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.898 + or -0.034 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.898 + or -0.033 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.898 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.904 + or -0.035 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.905 + or -0.034 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.905 + or -0.036 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.905 + or -0.036 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.912 + or -0.033 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.908 + or -0.035 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.911 + or -0.036 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.911 + or -0.039 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.907 + or -0.037 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.915 + or -0.037 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.909 + or -0.039 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.911 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.911 + or -0.037 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.909 + or -0.038 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.904 + or -0.036 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.911 + or -0.038 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.912 + or -0.033 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.914 + or -0.033 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.912 + or -0.029 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.753 + or -0.042 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.776 + or -0.035 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.793 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.82 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.835 + or -0.043 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.779 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.823 + or -0.037 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.848 + or -0.032 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.857 + or -0.036 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.873 + or -0.029 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.838 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.864 + or -0.043 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.886 + or -0.036 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.891 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.899 + or -0.034 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.864 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.895 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.901 + or -0.037 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.907 + or -0.032 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.92 + or -0.032 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.886 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.91 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.908 + or -0.038 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.914 + or -0.032 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.911 + or -0.035 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.891 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.912 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.911 + or -0.042 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.914 + or -0.034 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.909 + or -0.035 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.751 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.756 + or -0.042 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.757 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.752 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.749 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.781 + or -0.039 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.788 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.791 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.788 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.782 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.828 + or -0.042 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.835 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.837 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.842 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.845 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.854 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.864 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.869 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.873 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.879 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.87 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.874 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.886 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.891 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.893 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.877 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.892 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.901 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.898 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.904 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.845 + or -0.039 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.885 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.887 + or -0.034 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.886 + or -0.03 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.89 + or -0.033 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.886 + or -0.035 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.904 + or -0.021 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.905 + or -0.025 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.907 + or -0.026 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.904 + or -0.027 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.892 + or -0.039 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.904 + or -0.038 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.904 + or -0.024 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.901 + or -0.033 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.902 + or -0.032 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.886 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.899 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.901 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.901 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.902 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.904 + or -0.04 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.905 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.905 + or -0.042 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.908 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.908 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.892 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.908 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.902 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.908 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.907 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.747 + or -0.039 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.79 + or -0.034 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.809 + or -0.036 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.822 + or -0.04 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.841 + or -0.029 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.781 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.816 + or -0.042 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.836 + or -0.039 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.858 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.869 + or -0.035 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.816 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.848 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.874 + or -0.038 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.885 + or -0.04 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.889 + or -0.035 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.835 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.875 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.888 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.898 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.908 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.845 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.885 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.893 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.898 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.905 + or -0.033 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.858 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.888 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.895 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.901 + or -0.04 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.901 + or -0.036 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.695 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.728 + or -0.038 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.744 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.746 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.746 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.728 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.757 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.765 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.778 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.779 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.772 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.801 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.812 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.818 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.82 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.804 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.831 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.837 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.845 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.844 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.819 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.845 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.853 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.856 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.863 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.835 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.85 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.86 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.864 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.866 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9af5b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "XGBoost  average accuracy is 0.923\n",
      "XGBoost  average log_loss is 0.270\n",
      "XGBoost  average brier score is 0.074\n",
      "XGBoost  average auc is 0.975\n",
      "XGBoost  average recall is 0.938\n",
      "XGBoost  average precision is 0.911\n",
      "XGBoost  average f1 is 0.923\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42, n_estimators=700,\n",
    "                   max_depth = 15, learning_rate = 0.01, colsample_bytree = 0.3)\n",
    "xgb.fit(X,Y)\n",
    "\n",
    "showResults(xgb, \"XGBoost\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8510931e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X,Y, test_size=0.2, random_state=5)\n",
    "calibrated = CalibratedClassifierCV(xgb, method='sigmoid', cv=10)\n",
    "calibrated.fit(xtrain, ytrain)\n",
    "probs = calibrated.predict_proba(xtest)[:, 1]\n",
    "uncalibrated = xgb.predict_proba(xtest)[:,1]\n",
    "fop_uncalibrated, mpv_uncalibrated = calibration_curve(ytest, uncalibrated, n_bins=10, normalize=True)\n",
    "fop_calibrated, mpv_calibrated = calibration_curve(ytest, probs, n_bins=10, normalize=True)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label = 'Ideally Calibrated')\n",
    "plt.plot(mpv_uncalibrated, fop_uncalibrated, marker='.', label = 'XGBoost Uncalibrated')\n",
    "plt.plot(mpv_calibrated, fop_calibrated, marker='.', label = 'XGBoost Calibrated')\n",
    "leg = plt.legend(loc = 'upper left')\n",
    "plt.xlabel('Average Predicted Probability in each bin')\n",
    "plt.ylabel('Ratio of positives')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3ea50f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "XGBoost average accuracy is 0.920\n",
      "XGBoost average log_loss is 0.226\n",
      "XGBoost average brier score is 0.063\n",
      "XGBoost average auc is 0.974\n",
      "XGBoost average recall is 0.924\n",
      "XGBoost average precision is 0.918\n",
      "XGBoost average f1 is 0.919\n"
     ]
    }
   ],
   "source": [
    "calibrated = CalibratedClassifierCV(xgb, method='sigmoid', cv=10)\n",
    "\n",
    "scores_accuracy = cross_val_score(calibrated, X, Y, cv=10, scoring='accuracy')\n",
    "scores_log_loss = cross_val_score(calibrated, X, Y, cv=10, scoring='neg_log_loss')\n",
    "scores_briar = cross_val_score(calibrated, X, Y, cv=10, scoring='neg_brier_score')\n",
    "scores_auc = cross_val_score(calibrated, X, Y, cv=10, scoring='roc_auc')\n",
    "scores_recall = cross_val_score(calibrated, X, Y, cv=10, scoring='recall')\n",
    "scores_precision = cross_val_score(calibrated, X, Y, cv=10, scoring='precision')\n",
    "scores_f1 = cross_val_score(calibrated, X, Y, cv=10, scoring='f1')\n",
    "print('K-fold cross-validation results:')\n",
    "print(\"XGBoost average accuracy is %2.3f\" % scores_accuracy.mean())\n",
    "print(\"XGBoost average log_loss is %2.3f\" % -scores_log_loss.mean())\n",
    "print(\"XGBoost average brier score is %2.3f\" % -scores_briar.mean())\n",
    "print(\"XGBoost average auc is %2.3f\" % scores_auc.mean())\n",
    "print(\"XGBoost average recall is %2.3f\" % scores_recall.mean())\n",
    "print(\"XGBoost average precision is %2.3f\" % scores_precision.mean())\n",
    "print(\"XGBoost average f1 is %2.3f\" % scores_f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc84b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV + XGBoost\n",
    "X = X_balanced[['Age', 'Tscore_Hip_total', 'CRP', 'Cr', 'ALP', 'BUN', 'P', 'Ca', 'PTH', 'Vit_D3', \n",
    "       'BMD_vertebra', 'Tscore_vertebra', 'Zscore_vertebra', \n",
    "       'BMD_Hip_total', 'Zscore_hip_total', 'BMD_Hip_Neck', 'Tscore_Hip_neck', \n",
    "       'Zscore_Hip_neck', 'Histroy_Anticoagulant', 'Active_Smoking', \n",
    "       'History_Smoking', 'Calcium_Supplement', 'History_Diabetes_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa51ef3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 270 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_c...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.3, 0.5, 0.8],\n",
       "                         'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': [3, 4, 6, 8, 10, 15],\n",
       "                         'n_estimators': range(100, 1000, 200)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "cv = GridSearchCV(xgb,params,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ceec9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "Best Score is : 0.919693094629156 \n",
      "\n",
      "\n",
      "0.845 + or -0.076 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.873 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.896 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.899 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.899 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.847 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.889 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.901 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.907 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.904 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.892 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.898 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.899 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.902 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.905 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.898 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.898 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.899 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.901 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.902 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.908 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.911 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.911 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.911 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.912 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.901 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.902 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.904 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.908 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.904 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.79 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.81 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.814 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.836 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.847 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.81 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.833 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.847 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.852 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.857 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.855 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.87 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.89 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.902 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.901 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.879 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.905 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.907 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.914 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.912 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.898 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.918 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.918 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.917 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.915 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.904 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.915 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.912 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.915 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.92 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.785 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.785 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.788 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.79 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.795 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.806 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.82 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.823 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.822 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.825 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.846 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.847 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.849 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.852 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.858 + or -0.042 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.88 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.883 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.885 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.901 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.898 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.901 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.905 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.911 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.914 + or -0.042 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.912 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.899 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.91 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.912 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.912 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.914 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.835 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.863 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.886 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.895 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.896 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.858 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.901 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.906 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.905 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.905 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.892 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.898 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.905 + or -0.043 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.907 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.907 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.899 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.899 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.896 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.901 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.901 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.898 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.902 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.907 + or -0.042 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.908 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.906 + or -0.043 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.908 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.912 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.915 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.914 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.918 + or -0.042 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.776 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.794 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.811 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.823 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.832 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.817 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.814 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.833 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.845 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.855 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.858 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.848 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.86 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.877 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.887 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.88 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.87 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.883 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.886 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.893 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.885 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.886 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.887 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.895 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.901 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.889 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.885 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.889 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.901 + or -0.065 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.902 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.768 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.759 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.768 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.771 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.769 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.809 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.803 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.81 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.813 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.819 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.851 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.854 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.852 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.858 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.858 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.877 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.874 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.876 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.873 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.877 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.886 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.885 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.888 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.889 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.892 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.892 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.895 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.898 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.896 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.896 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.847 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.871 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.889 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.895 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.898 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.858 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.895 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.905 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.906 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.908 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.877 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.889 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.893 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.895 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.902 + or -0.039 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.877 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.895 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.901 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.902 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.901 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.886 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.899 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.899 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.904 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.906 + or -0.038 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.876 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.885 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.886 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.889 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.895 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.75 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.797 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.809 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.819 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.832 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.794 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.819 + or -0.082 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.83 + or -0.081 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.849 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.854 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.812 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.836 + or -0.084 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.845 + or -0.1 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.867 + or -0.086 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.879 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.832 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.849 + or -0.085 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.861 + or -0.091 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.871 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.88 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.845 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.86 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.863 + or -0.088 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.873 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.882 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.845 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.867 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.866 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.873 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.88 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.727 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.724 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.724 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.74 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.743 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.772 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.772 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.782 + or -0.038 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.778 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.788 + or -0.035 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.807 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.809 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.809 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.813 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.814 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.825 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.823 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.817 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.823 + or -0.07 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.826 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.825 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.826 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.826 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.826 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.831 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.835 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.835 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.832 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.833 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.839 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d0f67bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "XGBoost  average accuracy is 0.920\n",
      "XGBoost  average log_loss is 0.242\n",
      "XGBoost  average brier score is 0.068\n",
      "XGBoost  average auc is 0.973\n",
      "XGBoost  average recall is 0.953\n",
      "XGBoost  average precision is 0.895\n",
      "XGBoost  average f1 is 0.921\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42, n_estimators=900,\n",
    "                   max_depth = 15, learning_rate = 0.01, colsample_bytree = 0.3)\n",
    "xgb.fit(X,Y)\n",
    "\n",
    "showResults(xgb, \"XGBoost\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0c5fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV + CatBoost\n",
    "X = X_balanced[['Tscore_Hip_total', 'Cr', 'BMD_vertebra', 'Tscore_vertebra', 'Zscore_vertebra', \n",
    "                'BMD_Hip_total', 'Zscore_hip_total', 'BMD_Hip_Neck', 'Tscore_Hip_neck', 'Zscore_Hip_neck',\n",
    "                'Histroy_Anticoagulant', 'Active_Smoking', 'History_Smoking', 'Calcium_Supplement', \n",
    "                'History_Diabetes_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a983e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 270 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_c...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.3, 0.5, 0.8],\n",
       "                         'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': [3, 4, 6, 8, 10, 15],\n",
       "                         'n_estimators': range(100, 1000, 200)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "cv = GridSearchCV(xgb,params,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f625e5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "Best Score is : 0.8566069906223358 \n",
      "\n",
      "\n",
      "0.789 + or -0.086 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.813 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.819 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.817 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.823 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.81 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.82 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.832 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.845 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.846 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.824 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.845 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.849 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.848 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.848 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.824 + or -0.067 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.845 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.845 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.845 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.842 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.845 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.851 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.846 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.838 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.836 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.832 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.841 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.842 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.841 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.842 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.757 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.771 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.785 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.779 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.779 + or -0.08 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.785 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.791 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.801 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.8 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.807 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.8 + or -0.042 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.82 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.817 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.814 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.823 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.814 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.83 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.841 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.835 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.841 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.822 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.833 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.842 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.841 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.843 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.827 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.841 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.841 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.839 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.845 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.737 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.734 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.735 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.735 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.746 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.769 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.766 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.765 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.769 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.77 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.792 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.801 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.8 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.794 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.797 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.817 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.814 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.813 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.813 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.82 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.814 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.819 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.817 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.822 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.819 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.814 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.819 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.825 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.823 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.825 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.789 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.819 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.825 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.83 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.835 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.816 + or -0.09 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.842 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.845 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.848 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.848 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.825 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.845 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.844 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.842 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.848 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.835 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.845 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.851 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.846 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.846 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.845 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.849 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.848 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.848 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.851 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.851 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.847 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.847 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.845 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.849 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.757 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.765 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.778 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.791 + or -0.085 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.794 + or -0.089 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.775 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.797 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.803 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.809 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.816 + or -0.085 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.801 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.816 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.82 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.819 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.824 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.823 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.832 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.83 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.83 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.839 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.829 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.836 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.835 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.841 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.851 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.835 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.842 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.845 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.849 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.857 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.74 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.734 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.749 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.751 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.753 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.753 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.773 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.779 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.782 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.784 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.797 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.798 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.798 + or -0.042 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.803 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.801 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.82 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.814 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.817 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.819 + or -0.043 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.823 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.826 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.826 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.829 + or -0.039 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.829 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.832 + or -0.043 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.83 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.827 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.83 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.83 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.832 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.798 + or -0.087 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.826 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.836 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.835 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.842 + or -0.042 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.827 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.836 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.845 + or -0.042 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.844 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.848 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.845 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.851 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.851 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.845 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.846 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.83 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.838 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.845 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.851 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.849 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.832 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.848 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.848 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.851 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.849 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.839 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.845 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.851 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.854 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.855 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.738 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.759 + or -0.082 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.779 + or -0.083 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.786 + or -0.088 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.801 + or -0.088 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.768 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.779 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.795 + or -0.088 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.804 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.811 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.788 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.784 + or -0.09 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.805 + or -0.084 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.817 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.826 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.8 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.808 + or -0.086 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.82 + or -0.087 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.827 + or -0.084 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.832 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.806 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.816 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.822 + or -0.091 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.832 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.841 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.81 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.822 + or -0.081 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.826 + or -0.088 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.842 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.846 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.741 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.746 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.737 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.74 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.738 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.754 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.756 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.765 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.768 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.765 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.779 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.782 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.779 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.781 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.791 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.782 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.782 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.784 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.788 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.797 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.788 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.787 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.794 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.798 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.801 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.794 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.795 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.795 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.805 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.808 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdeb26d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "XGBoost  average accuracy is 0.857\n",
      "XGBoost  average log_loss is 0.358\n",
      "XGBoost  average brier score is 0.111\n",
      "XGBoost  average auc is 0.922\n",
      "XGBoost  average recall is 0.903\n",
      "XGBoost  average precision is 0.830\n",
      "XGBoost  average f1 is 0.863\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42, n_estimators=900,\n",
    "                   max_depth = 15, learning_rate = 0.01, colsample_bytree = 0.5)\n",
    "xgb.fit(X,Y)\n",
    "\n",
    "showResults(xgb, \"XGBoost\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56bd524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV + Logistic Regression\n",
    "X = X_balanced[['Tscore_Hip_total', 'Cr', 'BMD_vertebra', 'Tscore_vertebra', \n",
    "                'Zscore_vertebra', 'BMD_Hip_total', 'Zscore_hip_total', 'BMD_Hip_Neck', \n",
    "                'Tscore_Hip_neck', 'Zscore_Hip_neck', 'Histroy_Anticoagulant', 'Active_Smoking', \n",
    "                'History_Smoking', 'Calcium_Supplement', 'History_Diabetes_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1f0dd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 270 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_c...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.3, 0.5, 0.8],\n",
       "                         'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': [3, 4, 6, 8, 10, 15],\n",
       "                         'n_estimators': range(100, 1000, 200)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "cv = GridSearchCV(xgb,params,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb962820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "Best Score is : 0.8566069906223358 \n",
      "\n",
      "\n",
      "0.789 + or -0.086 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.813 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.819 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.817 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.823 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.81 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.82 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.832 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.845 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.846 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.824 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.845 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.849 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.848 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.848 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.824 + or -0.067 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.845 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.845 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.845 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.842 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.845 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.851 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.846 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.838 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.836 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.832 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.841 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.842 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.841 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.842 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.757 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.771 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.785 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.779 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.779 + or -0.08 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.785 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.791 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.801 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.8 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.807 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.8 + or -0.042 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.82 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.817 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.814 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.823 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.814 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.83 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.841 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.835 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.841 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.822 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.833 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.842 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.841 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.843 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.827 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.841 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.841 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.839 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.845 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.737 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.734 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.735 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.735 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.746 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.769 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.766 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.765 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.769 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.77 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.792 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.801 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.8 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.794 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.797 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.817 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.814 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.813 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.813 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.82 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.814 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.819 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.817 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.822 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.819 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.814 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.819 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.825 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.823 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.825 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.789 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.819 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.825 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.83 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.835 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.816 + or -0.09 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.842 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.845 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.848 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.848 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.825 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.845 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.844 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.842 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.848 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.835 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.845 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.851 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.846 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.846 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.845 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.849 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.848 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.848 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.851 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.851 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.847 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.847 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.845 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.849 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.757 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.765 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.778 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.791 + or -0.085 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.794 + or -0.089 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.775 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.797 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.803 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.809 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.816 + or -0.085 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.801 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.816 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.82 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.819 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.824 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.823 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.832 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.83 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.83 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.839 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.829 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.836 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.835 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.841 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.851 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.835 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.842 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.845 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.849 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.857 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.74 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.734 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.749 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.751 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.753 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.753 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.773 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.779 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.782 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.784 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.797 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.798 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.798 + or -0.042 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.803 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.801 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.82 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.814 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.817 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.819 + or -0.043 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.823 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.826 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.826 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.829 + or -0.039 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.829 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.832 + or -0.043 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.83 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.827 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.83 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.83 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.832 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.798 + or -0.087 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.826 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.836 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.835 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.842 + or -0.042 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.827 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.836 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.845 + or -0.042 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.844 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.848 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.845 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.851 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.851 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.845 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.846 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.83 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.838 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.845 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.851 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.849 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.832 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.848 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.848 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.851 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.849 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.839 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.845 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.851 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.854 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.855 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.738 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.759 + or -0.082 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.779 + or -0.083 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.786 + or -0.088 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.801 + or -0.088 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.768 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.779 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.795 + or -0.088 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.804 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.811 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.788 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.784 + or -0.09 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.805 + or -0.084 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.817 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.826 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.8 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.808 + or -0.086 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.82 + or -0.087 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.827 + or -0.084 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.832 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.806 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.816 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.822 + or -0.091 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.832 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.841 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.81 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.822 + or -0.081 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.826 + or -0.088 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.842 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.846 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.741 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.746 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.737 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.74 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.738 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.754 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.756 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.765 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.768 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.765 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.779 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.782 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.779 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.781 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.791 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.782 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.782 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.784 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.788 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.797 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.788 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.787 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.794 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.798 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.801 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.794 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.795 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.795 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.805 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.808 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6591abb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "XGBoost  average accuracy is 0.857\n",
      "XGBoost  average log_loss is 0.358\n",
      "XGBoost  average brier score is 0.111\n",
      "XGBoost  average auc is 0.922\n",
      "XGBoost  average recall is 0.903\n",
      "XGBoost  average precision is 0.830\n",
      "XGBoost  average f1 is 0.863\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42, n_estimators=900,\n",
    "                   max_depth = 15, learning_rate = 0.01, colsample_bytree = 0.5)\n",
    "xgb.fit(X,Y)\n",
    "\n",
    "showResults(xgb, \"XGBoost\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cc78081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV + LightGBM\n",
    "X = X_balanced[['Tscore_Hip_total', 'CRP', 'Cr', 'ALP', 'BUN', 'P', 'Ca', 'PTH', 'Vit_D3',\n",
    "                'Tscore_vertebra', 'Zscore_vertebra', 'BMD_Hip_total', 'Tscore_Hip_neck', 'BMI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ae536ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 270 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_c...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.3, 0.5, 0.8],\n",
       "                         'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': [3, 4, 6, 8, 10, 15],\n",
       "                         'n_estimators': range(100, 1000, 200)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "cv = GridSearchCV(xgb,params,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b7813f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "Best Score is : 0.9093989769820972 \n",
      "\n",
      "\n",
      "0.822 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.866 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.861 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.871 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.871 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.86 + or -0.04 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.892 + or -0.032 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.888 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.889 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.889 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.888 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.896 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.893 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.898 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.899 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.89 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.898 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.899 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.896 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.892 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.882 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.889 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.896 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.899 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.892 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.889 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.885 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.889 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.889 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.888 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.737 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.757 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.784 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.803 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.807 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.782 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.814 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.838 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.845 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.854 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.838 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.861 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.879 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.889 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.89 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.864 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.889 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.901 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.902 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.904 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.871 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.898 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.901 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.902 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.901 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.892 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.904 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.899 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.902 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.901 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.706 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.727 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.731 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.731 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.738 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.765 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.776 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.776 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.779 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.785 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.822 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.836 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.847 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.844 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.852 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.852 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.869 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.869 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.864 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.87 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.867 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.886 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.893 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.889 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.89 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.876 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.891 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.899 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.896 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.901 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.819 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.872 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.877 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.874 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.88 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.874 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.887 + or -0.039 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.893 + or -0.043 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.899 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.901 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.901 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.902 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.904 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.902 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.904 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.886 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.895 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.895 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.895 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.899 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.895 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.899 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.899 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.904 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.905 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.896 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.899 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.898 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.898 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.896 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.715 + or -0.037 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.755 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.794 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.815 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.828 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.766 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.8 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.832 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.861 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.866 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.823 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.86 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.877 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.883 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.891 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.86 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.883 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.899 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.901 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.899 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.873 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.895 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.904 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.905 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.905 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.882 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.902 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.905 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.905 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.905 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.705 + or -0.038 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.709 + or -0.03 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.719 + or -0.033 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.724 + or -0.034 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.719 + or -0.035 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.753 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.762 + or -0.043 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.774 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.775 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.774 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.809 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.822 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.823 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.82 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.823 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.834 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.85 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.853 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.861 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.858 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.857 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.864 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.87 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.873 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.876 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.861 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.866 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.87 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.875 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.875 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.847 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.888 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.888 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.893 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.889 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.885 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.893 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.896 + or -0.037 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.908 + or -0.037 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.909 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.891 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.892 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.895 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.896 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.899 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.883 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.886 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.893 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.892 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.889 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.883 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.891 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.892 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.893 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.893 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.871 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.88 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.888 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.886 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.889 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.712 + or -0.036 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.759 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.793 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.816 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.835 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.75 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.796 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.838 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.863 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.872 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.794 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.85 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.876 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.895 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.893 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.807 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.866 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.88 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.892 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.893 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.816 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.869 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.883 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.888 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.892 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.817 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.867 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.885 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.891 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.891 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.68 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.684 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.705 + or -0.038 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.708 + or -0.035 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.712 + or -0.039 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.702 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.737 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.753 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.749 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.753 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.76 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.779 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.788 + or -0.07 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.799 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.794 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.782 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.799 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.8 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.806 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.807 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.793 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.798 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.806 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.812 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.812 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.809 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.813 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.817 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.822 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.825 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2df24c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "XGBoost  average accuracy is 0.909\n",
      "XGBoost  average log_loss is 0.264\n",
      "XGBoost  average brier score is 0.075\n",
      "XGBoost  average auc is 0.963\n",
      "XGBoost  average recall is 0.965\n",
      "XGBoost  average precision is 0.871\n",
      "XGBoost  average f1 is 0.915\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42, n_estimators=900,\n",
    "                   max_depth = 4, learning_rate = 0.1, colsample_bytree = 0.8)\n",
    "xgb.fit(X,Y)\n",
    "\n",
    "showResults(xgb, \"XGBoost\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdcbd443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV + ADABoost\n",
    "X = X_balanced[['Cr', 'ALP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "255f5991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 270 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_c...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.3, 0.5, 0.8],\n",
       "                         'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': [3, 4, 6, 8, 10, 15],\n",
       "                         'n_estimators': range(100, 1000, 200)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "cv = GridSearchCV(xgb,params,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3325727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "Best Score is : 0.5891304347826087 \n",
      "\n",
      "\n",
      "0.571 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.574 + or -0.067 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.561 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.555 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.55 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.57 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.547 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.541 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.52 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.52 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.545 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.528 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.523 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.522 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.517 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.526 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.514 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.516 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.516 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.515 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.529 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.519 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.528 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.517 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.519 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.52 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.533 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.528 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.529 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.519 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.564 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.564 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.589 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.573 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.557 + or -0.065 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.567 + or -0.071 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.574 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.576 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.576 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.579 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.538 + or -0.078 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.538 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.532 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.539 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.535 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.538 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.532 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.536 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.542 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.536 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.523 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.519 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.516 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.522 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.522 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.512 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.512 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.516 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.52 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.519 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.572 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.569 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.57 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.57 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.577 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.573 + or -0.076 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.57 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.558 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.569 + or -0.078 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.576 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.541 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.538 + or -0.065 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.544 + or -0.078 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.545 + or -0.08 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.539 + or -0.071 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.522 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.522 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.539 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.533 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.539 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.523 + or -0.067 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.513 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.525 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.525 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.52 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.517 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.506 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.516 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.513 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.509 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.571 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.574 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.561 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.555 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.55 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.57 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.547 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.541 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.52 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.52 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.545 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.528 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.523 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.522 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.517 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.526 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.514 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.516 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.516 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.515 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.529 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.519 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.528 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.517 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.519 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.52 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.533 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.528 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.529 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.519 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.564 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.564 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.589 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.573 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.557 + or -0.065 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.567 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.574 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.576 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.576 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.579 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.538 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.538 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.532 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.539 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.535 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.538 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.532 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.536 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.542 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.536 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.523 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.519 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.516 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.522 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.522 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.512 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.512 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.516 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.52 + or -0.039 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.519 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.572 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.569 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.57 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.57 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.577 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.573 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.57 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.558 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.569 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.576 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.541 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.538 + or -0.065 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.544 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.545 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.539 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.522 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.522 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.539 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.533 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.539 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.523 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.513 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.525 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.525 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.52 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.517 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.506 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.516 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.513 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.509 + or -0.043 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.571 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.574 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.561 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.555 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.55 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.57 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.547 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.541 + or -0.07 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.52 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.52 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.545 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.528 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.523 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.522 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.517 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.526 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.514 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.516 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.516 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.515 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.529 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.519 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.528 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.517 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.519 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.52 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.533 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.528 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.529 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.519 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.564 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.564 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.589 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.573 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.557 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.567 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.574 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.576 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.576 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.579 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.538 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.538 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.532 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.539 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.535 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.538 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.532 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.536 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.542 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.536 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.523 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.519 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.516 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.522 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.522 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.512 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.512 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.516 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.52 + or -0.039 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.519 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.572 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.569 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.57 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.57 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.577 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.573 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.57 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.558 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.569 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.576 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.541 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.538 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.544 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.545 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.539 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.522 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.522 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.539 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.533 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.539 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.523 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.513 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.525 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.525 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.52 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.517 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.506 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.516 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.513 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.509 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e2582c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "XGBoost  average accuracy is 0.589\n",
      "XGBoost  average log_loss is 0.688\n",
      "XGBoost  average brier score is 0.246\n",
      "XGBoost  average auc is 0.597\n",
      "XGBoost  average recall is 0.628\n",
      "XGBoost  average precision is 0.587\n",
      "XGBoost  average f1 is 0.604\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42, n_estimators=500,\n",
    "                   max_depth = 3, learning_rate = 0.01, colsample_bytree = 0.3)\n",
    "xgb.fit(X,Y)\n",
    "\n",
    "showResults(xgb, \"XGBoost\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdfd7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
