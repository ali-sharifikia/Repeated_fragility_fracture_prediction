{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "badb7797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import normalize,StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, GridSearchCV,train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss,roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.calibration import calibration_curve\n",
    "from xgboost import XGBClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcf644c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Menopause_age</th>\n",
       "      <th>Tscore_Hip_total</th>\n",
       "      <th>CRP</th>\n",
       "      <th>Cr</th>\n",
       "      <th>ALP</th>\n",
       "      <th>BUN</th>\n",
       "      <th>P</th>\n",
       "      <th>Ca</th>\n",
       "      <th>...</th>\n",
       "      <th>Tscore_Hip_neck</th>\n",
       "      <th>Zscore_Hip_neck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pregnancy_Count</th>\n",
       "      <th>Histroy_Anticoagulant</th>\n",
       "      <th>Active_Smoking</th>\n",
       "      <th>History_Smoking</th>\n",
       "      <th>Calcium_Supplement</th>\n",
       "      <th>History_Diabetes_2</th>\n",
       "      <th>Refracture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>320.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.9</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>170.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>8.9</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>28.300000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>190.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8.9</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>175.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>290.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>8.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>33.200000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>707</td>\n",
       "      <td>77</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>28.827532</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>708</td>\n",
       "      <td>65</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>123.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>9.6</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>28.827532</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>709</td>\n",
       "      <td>62</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>201.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>28.827532</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>710</td>\n",
       "      <td>56</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>28.827532</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>711</td>\n",
       "      <td>53</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>28.827532</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Age  Menopause_age  Tscore_Hip_total   CRP   Cr    ALP   BUN  \\\n",
       "0             0   66           50.0              -1.6   5.0  1.1  320.0  25.0   \n",
       "1             1   65           50.0              -2.6   6.0  0.7  170.0  17.0   \n",
       "2             2   72           40.0              -1.7  29.0  0.7  190.0  19.0   \n",
       "3             3   62           40.0              -0.2   1.0  0.9  175.0  16.0   \n",
       "4             4   76           50.0              -1.6  13.0  1.2  290.0  23.0   \n",
       "..          ...  ...            ...               ...   ...  ...    ...   ...   \n",
       "707         707   77           50.0              -2.2  11.0  1.0  134.0  11.0   \n",
       "708         708   65           50.0              -1.0  33.0  0.8  123.0  12.0   \n",
       "709         709   62           50.0              -0.1  19.0  0.9  201.0  12.0   \n",
       "710         710   56           50.0               0.1  32.0  1.0  153.0  16.0   \n",
       "711         711   53           50.0               1.9   1.0  1.0  191.0  13.0   \n",
       "\n",
       "       P   Ca  ...  Tscore_Hip_neck  Zscore_Hip_neck        BMI  \\\n",
       "0    4.5  8.9  ...             -2.3             -0.8  26.700000   \n",
       "1    4.2  8.9  ...             -3.5             -2.0  28.300000   \n",
       "2    4.3  8.9  ...             -3.0             -1.1  24.400000   \n",
       "3    3.2  8.8  ...             -1.5              0.7  22.600000   \n",
       "4    3.3  8.5  ...             -1.8              0.3  33.200000   \n",
       "..   ...  ...  ...              ...              ...        ...   \n",
       "707  3.7  9.2  ...             -2.9             -0.8  28.827532   \n",
       "708  2.3  9.6  ...             -2.0             -0.5  28.827532   \n",
       "709  4.7  8.8  ...             -2.0             -0.7  28.827532   \n",
       "710  4.0  8.8  ...             -1.2             -0.2  28.827532   \n",
       "711  3.0  9.0  ...              0.3              1.2  28.827532   \n",
       "\n",
       "     Pregnancy_Count  Histroy_Anticoagulant  Active_Smoking  History_Smoking  \\\n",
       "0               13.0                      0               0                0   \n",
       "1               12.0                      1               0                0   \n",
       "2               12.0                      0               0                0   \n",
       "3               12.0                      0               0                0   \n",
       "4               10.0                      0               0                0   \n",
       "..               ...                    ...             ...              ...   \n",
       "707              4.0                      0               0                0   \n",
       "708              4.0                      0               0                0   \n",
       "709              4.0                      0               0                0   \n",
       "710              4.0                      0               0                0   \n",
       "711              4.0                      0               0                0   \n",
       "\n",
       "     Calcium_Supplement  History_Diabetes_2  Refracture  \n",
       "0                     0                   0           0  \n",
       "1                     0                   0           0  \n",
       "2                     0                   0           0  \n",
       "3                     0                   0           0  \n",
       "4                     0                   0           1  \n",
       "..                  ...                 ...         ...  \n",
       "707                   0                   0           1  \n",
       "708                   0                   0           1  \n",
       "709                   0                   0           0  \n",
       "710                   0                   0           0  \n",
       "711                   0                   0           0  \n",
       "\n",
       "[712 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dataset = pd.read_csv(\"Dataset_Female_Final.csv\")\n",
    "display(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdfe2929",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.drop(\"Unnamed: 0\", axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37848cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Menopause_age</th>\n",
       "      <th>Tscore_Hip_total</th>\n",
       "      <th>CRP</th>\n",
       "      <th>Cr</th>\n",
       "      <th>ALP</th>\n",
       "      <th>BUN</th>\n",
       "      <th>P</th>\n",
       "      <th>Ca</th>\n",
       "      <th>PTH</th>\n",
       "      <th>...</th>\n",
       "      <th>Tscore_Hip_neck</th>\n",
       "      <th>Zscore_Hip_neck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pregnancy_Count</th>\n",
       "      <th>Histroy_Anticoagulant</th>\n",
       "      <th>Active_Smoking</th>\n",
       "      <th>History_Smoking</th>\n",
       "      <th>Calcium_Supplement</th>\n",
       "      <th>History_Diabetes_2</th>\n",
       "      <th>Refracture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>320.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.9</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>170.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>8.9</td>\n",
       "      <td>31.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>28.300000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>190.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8.9</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>175.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>290.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>8.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>33.200000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>77</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>60.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>28.827532</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>65</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>123.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>9.6</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>28.827532</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>62</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>201.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>185.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>28.827532</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>56</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>28.827532</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>53</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>28.827532</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Menopause_age  Tscore_Hip_total   CRP   Cr    ALP   BUN    P   Ca  \\\n",
       "0     66           50.0              -1.6   5.0  1.1  320.0  25.0  4.5  8.9   \n",
       "1     65           50.0              -2.6   6.0  0.7  170.0  17.0  4.2  8.9   \n",
       "2     72           40.0              -1.7  29.0  0.7  190.0  19.0  4.3  8.9   \n",
       "3     62           40.0              -0.2   1.0  0.9  175.0  16.0  3.2  8.8   \n",
       "4     76           50.0              -1.6  13.0  1.2  290.0  23.0  3.3  8.5   \n",
       "..   ...            ...               ...   ...  ...    ...   ...  ...  ...   \n",
       "707   77           50.0              -2.2  11.0  1.0  134.0  11.0  3.7  9.2   \n",
       "708   65           50.0              -1.0  33.0  0.8  123.0  12.0  2.3  9.6   \n",
       "709   62           50.0              -0.1  19.0  0.9  201.0  12.0  4.7  8.8   \n",
       "710   56           50.0               0.1  32.0  1.0  153.0  16.0  4.0  8.8   \n",
       "711   53           50.0               1.9   1.0  1.0  191.0  13.0  3.0  9.0   \n",
       "\n",
       "       PTH  ...  Tscore_Hip_neck  Zscore_Hip_neck        BMI  Pregnancy_Count  \\\n",
       "0     35.0  ...             -2.3             -0.8  26.700000             13.0   \n",
       "1     31.4  ...             -3.5             -2.0  28.300000             12.0   \n",
       "2     42.0  ...             -3.0             -1.1  24.400000             12.0   \n",
       "3     53.0  ...             -1.5              0.7  22.600000             12.0   \n",
       "4     65.0  ...             -1.8              0.3  33.200000             10.0   \n",
       "..     ...  ...              ...              ...        ...              ...   \n",
       "707   60.7  ...             -2.9             -0.8  28.827532              4.0   \n",
       "708   48.0  ...             -2.0             -0.5  28.827532              4.0   \n",
       "709  185.0  ...             -2.0             -0.7  28.827532              4.0   \n",
       "710   68.0  ...             -1.2             -0.2  28.827532              4.0   \n",
       "711   53.0  ...              0.3              1.2  28.827532              4.0   \n",
       "\n",
       "     Histroy_Anticoagulant  Active_Smoking  History_Smoking  \\\n",
       "0                        0               0                0   \n",
       "1                        1               0                0   \n",
       "2                        0               0                0   \n",
       "3                        0               0                0   \n",
       "4                        0               0                0   \n",
       "..                     ...             ...              ...   \n",
       "707                      0               0                0   \n",
       "708                      0               0                0   \n",
       "709                      0               0                0   \n",
       "710                      0               0                0   \n",
       "711                      0               0                0   \n",
       "\n",
       "     Calcium_Supplement  History_Diabetes_2  Refracture  \n",
       "0                     0                   0           0  \n",
       "1                     0                   0           0  \n",
       "2                     0                   0           0  \n",
       "3                     0                   0           0  \n",
       "4                     0                   0           1  \n",
       "..                  ...                 ...         ...  \n",
       "707                   0                   0           1  \n",
       "708                   0                   0           1  \n",
       "709                   0                   0           0  \n",
       "710                   0                   0           0  \n",
       "711                   0                   0           0  \n",
       "\n",
       "[712 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32dbe64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Menopause_age', 'Tscore_Hip_total', 'CRP', 'Cr', 'ALP', 'BUN',\n",
       "       'P', 'Ca', 'PTH', 'Vit_D3', 'BMD_vertebra', 'Tscore_vertebra',\n",
       "       'Zscore_vertebra', 'BMD_Hip_total', 'Zscore_hip_total', 'BMD_Hip_Neck',\n",
       "       'Tscore_Hip_neck', 'Zscore_Hip_neck', 'BMI', 'Pregnancy_Count',\n",
       "       'Histroy_Anticoagulant', 'Active_Smoking', 'History_Smoking',\n",
       "       'Calcium_Supplement', 'History_Diabetes_2', 'Refracture'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d7f1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Column Identified outliers: 1\n",
      "Age Column Identified outliers: 0\n",
      "Tscore_Hip_total Column Identified outliers: 3\n",
      "Tscore_Hip_total Column Identified outliers: 0\n",
      "CRP Column Identified outliers: 25\n",
      "CRP Column Identified outliers: 0\n",
      "Cr Column Identified outliers: 11\n",
      "Cr Column Identified outliers: 0\n",
      "ALP Column Identified outliers: 11\n",
      "ALP Column Identified outliers: 0\n",
      "BUN Column Identified outliers: 15\n",
      "BUN Column Identified outliers: 0\n",
      "P Column Identified outliers: 4\n",
      "P Column Identified outliers: 0\n",
      "Ca Column Identified outliers: 6\n",
      "Ca Column Identified outliers: 0\n",
      "PTH Column Identified outliers: 5\n",
      "PTH Column Identified outliers: 0\n",
      "Vit_D3 Column Identified outliers: 10\n",
      "Vit_D3 Column Identified outliers: 0\n",
      "BMD_vertebra Column Identified outliers: 4\n",
      "BMD_vertebra Column Identified outliers: 0\n",
      "Tscore_vertebra Column Identified outliers: 5\n",
      "Tscore_vertebra Column Identified outliers: 0\n",
      "Zscore_vertebra Column Identified outliers: 4\n",
      "Zscore_vertebra Column Identified outliers: 0\n",
      "BMD_Hip_total Column Identified outliers: 6\n",
      "BMD_Hip_total Column Identified outliers: 0\n",
      "Zscore_hip_total Column Identified outliers: 4\n",
      "Zscore_hip_total Column Identified outliers: 0\n",
      "BMD_Hip_Neck Column Identified outliers: 3\n",
      "BMD_Hip_Neck Column Identified outliers: 0\n",
      "Tscore_Hip_neck Column Identified outliers: 5\n",
      "Tscore_Hip_neck Column Identified outliers: 0\n",
      "Zscore_Hip_neck Column Identified outliers: 4\n",
      "Zscore_Hip_neck Column Identified outliers: 0\n",
      "BMI Column Identified outliers: 1\n",
      "BMI Column Identified outliers: 0\n",
      "Menopause_age Column Identified outliers: 11\n",
      "Menopause_age Column Identified outliers: 0\n",
      "Pregnancy_Count Column Identified outliers: 6\n",
      "Pregnancy_Count Column Identified outliers: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Age'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Tscore_Hip_total'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Tscore_Hip_total'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['CRP'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Cr'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['ALP'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['BUN'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['P'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['P'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Ca'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Ca'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:173: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['PTH'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:193: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Vit_D3'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['BMD_vertebra'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['BMD_vertebra'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:233: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Tscore_vertebra'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:253: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Zscore_vertebra'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:268: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['BMD_Hip_total'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['BMD_Hip_total'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Zscore_hip_total'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:293: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Zscore_hip_total'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['BMD_Hip_Neck'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:313: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['BMD_Hip_Neck'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:328: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Tscore_Hip_neck'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:333: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Tscore_Hip_neck'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:348: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Zscore_Hip_neck'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:353: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Zscore_Hip_neck'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:374: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['BMI'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:389: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Menopause_age'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:394: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Menopause_age'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_52748\\3804175493.py:413: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Pregnancy_Count'][i] = upper\n"
     ]
    }
   ],
   "source": [
    "data_mean, data_std = np.mean(Dataset['Age']), np.std(Dataset['Age'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Age'] if x < lower or x > upper]\n",
    "print('Age Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Age'])):\n",
    "    if Dataset['Age'][i] < lower:\n",
    "        Dataset['Age'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Age'])):\n",
    "    if Dataset['Age'][i] > upper:\n",
    "        Dataset['Age'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Age'] if x < lower or x > upper]\n",
    "print('Age Column Identified outliers: %d' % len(outliers))\n",
    "###########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Tscore_Hip_total']), np.std(Dataset['Tscore_Hip_total'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Tscore_Hip_total'] if x < lower or x > upper]\n",
    "print('Tscore_Hip_total Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Tscore_Hip_total'])):\n",
    "    if Dataset['Tscore_Hip_total'][i] < lower:\n",
    "        Dataset['Tscore_Hip_total'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Tscore_Hip_total'])):\n",
    "    if Dataset['Tscore_Hip_total'][i] > upper:\n",
    "        Dataset['Tscore_Hip_total'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Tscore_Hip_total'] if x < lower or x > upper]\n",
    "print('Tscore_Hip_total Column Identified outliers: %d' % len(outliers))\n",
    "#########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['CRP']), np.std(Dataset['CRP'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['CRP'] if x < lower or x > upper]\n",
    "print('CRP Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['CRP'])):\n",
    "    if Dataset['CRP'][i] < lower:\n",
    "        Dataset['CRP'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['CRP'])):\n",
    "    if Dataset['CRP'][i] > upper:\n",
    "        Dataset['CRP'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['CRP'] if x < lower or x > upper]\n",
    "print('CRP Column Identified outliers: %d' % len(outliers))\n",
    "########################################################################################\n",
    "data_mean, data_std = np.mean(Dataset['Cr']), np.std(Dataset['Cr'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Cr'] if x < lower or x > upper]\n",
    "print('Cr Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Cr'])):\n",
    "    if Dataset['Cr'][i] < lower:\n",
    "        Dataset['Cr'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Cr'])):\n",
    "    if Dataset['Cr'][i] > upper:\n",
    "        Dataset['Cr'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Cr'] if x < lower or x > upper]\n",
    "print('Cr Column Identified outliers: %d' % len(outliers))\n",
    "###########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['ALP']), np.std(Dataset['ALP'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['ALP'] if x < lower or x > upper]\n",
    "print('ALP Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['ALP'])):\n",
    "    if Dataset['ALP'][i] < lower:\n",
    "        Dataset['ALP'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['ALP'])):\n",
    "    if Dataset['ALP'][i] > upper:\n",
    "        Dataset['ALP'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['ALP'] if x < lower or x > upper]\n",
    "print('ALP Column Identified outliers: %d' % len(outliers))\n",
    "##########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['BUN']), np.std(Dataset['BUN'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['BUN'] if x < lower or x > upper]\n",
    "print('BUN Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['BUN'])):\n",
    "    if Dataset['BUN'][i] < lower:\n",
    "        Dataset['BUN'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['BUN'])):\n",
    "    if Dataset['BUN'][i] > upper:\n",
    "        Dataset['BUN'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['BUN'] if x < lower or x > upper]\n",
    "print('BUN Column Identified outliers: %d' % len(outliers))\n",
    "#############################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['P']), np.std(Dataset['P'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['P'] if x < lower or x > upper]\n",
    "print('P Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['P'])):\n",
    "    if Dataset['P'][i] < lower:\n",
    "        Dataset['P'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['P'])):\n",
    "    if Dataset['P'][i] > upper:\n",
    "        Dataset['P'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['P'] if x < lower or x > upper]\n",
    "print('P Column Identified outliers: %d' % len(outliers))\n",
    "##############################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Ca']), np.std(Dataset['Ca'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Ca'] if x < lower or x > upper]\n",
    "print('Ca Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Ca'])):\n",
    "    if Dataset['Ca'][i] < lower:\n",
    "        Dataset['Ca'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Ca'])):\n",
    "    if Dataset['Ca'][i] > upper:\n",
    "        Dataset['Ca'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Ca'] if x < lower or x > upper]\n",
    "print('Ca Column Identified outliers: %d' % len(outliers))\n",
    "############################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['PTH']), np.std(Dataset['PTH'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['PTH'] if x < lower or x > upper]\n",
    "print('PTH Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['PTH'])):\n",
    "    if Dataset['PTH'][i] < lower:\n",
    "        Dataset['PTH'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['PTH'])):\n",
    "    if Dataset['PTH'][i] > upper:\n",
    "        Dataset['PTH'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['PTH'] if x < lower or x > upper]\n",
    "print('PTH Column Identified outliers: %d' % len(outliers))\n",
    "##########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Vit_D3']), np.std(Dataset['Vit_D3'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Vit_D3'] if x < lower or x > upper]\n",
    "print('Vit_D3 Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Vit_D3'])):\n",
    "    if Dataset['Vit_D3'][i] < lower:\n",
    "        Dataset['Vit_D3'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Vit_D3'])):\n",
    "    if Dataset['Vit_D3'][i] > upper:\n",
    "        Dataset['Vit_D3'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Vit_D3'] if x < lower or x > upper]\n",
    "print('Vit_D3 Column Identified outliers: %d' % len(outliers))\n",
    "########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['BMD_vertebra']), np.std(Dataset['BMD_vertebra'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['BMD_vertebra'] if x < lower or x > upper]\n",
    "print('BMD_vertebra Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['BMD_vertebra'])):\n",
    "    if Dataset['BMD_vertebra'][i] < lower:\n",
    "        Dataset['BMD_vertebra'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['BMD_vertebra'])):\n",
    "    if Dataset['BMD_vertebra'][i] > upper:\n",
    "        Dataset['BMD_vertebra'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['BMD_vertebra'] if x < lower or x > upper]\n",
    "print('BMD_vertebra Column Identified outliers: %d' % len(outliers))\n",
    "############################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Tscore_vertebra']), np.std(Dataset['Tscore_vertebra'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Tscore_vertebra'] if x < lower or x > upper]\n",
    "print('Tscore_vertebra Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Tscore_vertebra'])):\n",
    "    if Dataset['Tscore_vertebra'][i] < lower:\n",
    "        Dataset['Tscore_vertebra'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Tscore_vertebra'])):\n",
    "    if Dataset['Tscore_vertebra'][i] > upper:\n",
    "        Dataset['Tscore_vertebra'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Tscore_vertebra'] if x < lower or x > upper]\n",
    "print('Tscore_vertebra Column Identified outliers: %d' % len(outliers))\n",
    "##########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Zscore_vertebra']), np.std(Dataset['Zscore_vertebra'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Zscore_vertebra'] if x < lower or x > upper]\n",
    "print('Zscore_vertebra Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Zscore_vertebra'])):\n",
    "    if Dataset['Zscore_vertebra'][i] < lower:\n",
    "        Dataset['Zscore_vertebra'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Zscore_vertebra'])):\n",
    "    if Dataset['Zscore_vertebra'][i] > upper:\n",
    "        Dataset['Zscore_vertebra'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Zscore_vertebra'] if x < lower or x > upper]\n",
    "print('Zscore_vertebra Column Identified outliers: %d' % len(outliers))\n",
    "########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['BMD_Hip_total']), np.std(Dataset['BMD_Hip_total'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['BMD_Hip_total'] if x < lower or x > upper]\n",
    "print('BMD_Hip_total Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['BMD_Hip_total'])):\n",
    "    if Dataset['BMD_Hip_total'][i] < lower:\n",
    "        Dataset['BMD_Hip_total'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['BMD_Hip_total'])):\n",
    "    if Dataset['BMD_Hip_total'][i] > upper:\n",
    "        Dataset['BMD_Hip_total'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['BMD_Hip_total'] if x < lower or x > upper]\n",
    "print('BMD_Hip_total Column Identified outliers: %d' % len(outliers))\n",
    "############################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Zscore_hip_total']), np.std(Dataset['Zscore_hip_total'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Zscore_hip_total'] if x < lower or x > upper]\n",
    "print('Zscore_hip_total Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Zscore_hip_total'])):\n",
    "    if Dataset['Zscore_hip_total'][i] < lower:\n",
    "        Dataset['Zscore_hip_total'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Zscore_hip_total'])):\n",
    "    if Dataset['Zscore_hip_total'][i] > upper:\n",
    "        Dataset['Zscore_hip_total'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Zscore_hip_total'] if x < lower or x > upper]\n",
    "print('Zscore_hip_total Column Identified outliers: %d' % len(outliers))\n",
    "##########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['BMD_Hip_Neck']), np.std(Dataset['BMD_Hip_Neck'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['BMD_Hip_Neck'] if x < lower or x > upper]\n",
    "print('BMD_Hip_Neck Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['BMD_Hip_Neck'])):\n",
    "    if Dataset['BMD_Hip_Neck'][i] < lower:\n",
    "        Dataset['BMD_Hip_Neck'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['BMD_Hip_Neck'])):\n",
    "    if Dataset['BMD_Hip_Neck'][i] > upper:\n",
    "        Dataset['BMD_Hip_Neck'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['BMD_Hip_Neck'] if x < lower or x > upper]\n",
    "print('BMD_Hip_Neck Column Identified outliers: %d' % len(outliers))\n",
    "########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Tscore_Hip_neck']), np.std(Dataset['Tscore_Hip_neck'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Tscore_Hip_neck'] if x < lower or x > upper]\n",
    "print('Tscore_Hip_neck Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Tscore_Hip_neck'])):\n",
    "    if Dataset['Tscore_Hip_neck'][i] < lower:\n",
    "        Dataset['Tscore_Hip_neck'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Tscore_Hip_neck'])):\n",
    "    if Dataset['Tscore_Hip_neck'][i] > upper:\n",
    "        Dataset['Tscore_Hip_neck'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Tscore_Hip_neck'] if x < lower or x > upper]\n",
    "print('Tscore_Hip_neck Column Identified outliers: %d' % len(outliers))\n",
    "############################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Zscore_Hip_neck']), np.std(Dataset['Zscore_Hip_neck'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Zscore_Hip_neck'] if x < lower or x > upper]\n",
    "print('Zscore_Hip_neck Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Zscore_Hip_neck'])):\n",
    "    if Dataset['Zscore_Hip_neck'][i] < lower:\n",
    "        Dataset['Zscore_Hip_neck'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Zscore_Hip_neck'])):\n",
    "    if Dataset['Zscore_Hip_neck'][i] > upper:\n",
    "        Dataset['Zscore_Hip_neck'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Zscore_Hip_neck'] if x < lower or x > upper]\n",
    "print('Zscore_Hip_neck Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['BMI']), np.std(Dataset['BMI'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['BMI'] if x < lower or x > upper]\n",
    "print('BMI Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['BMI'])):\n",
    "    if Dataset['BMI'][i] < lower:\n",
    "        Dataset['BMI'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['BMI'])):\n",
    "    if Dataset['BMI'][i] > upper:\n",
    "        Dataset['BMI'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['BMI'] if x < lower or x > upper]\n",
    "print('BMI Column Identified outliers: %d' % len(outliers))\n",
    "########################################################################################\n",
    "\n",
    "data_mean, data_std = np.mean(Dataset['Menopause_age']), np.std(Dataset['Menopause_age'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Menopause_age'] if x < lower or x > upper]\n",
    "print('Menopause_age Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Menopause_age'])):\n",
    "    if Dataset['Menopause_age'][i] < lower:\n",
    "        Dataset['Menopause_age'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Menopause_age'])):\n",
    "    if Dataset['Menopause_age'][i] > upper:\n",
    "        Dataset['Menopause_age'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Menopause_age'] if x < lower or x > upper]\n",
    "print('Menopause_age Column Identified outliers: %d' % len(outliers))\n",
    "###########################################################################################\n",
    "data_mean, data_std = np.mean(Dataset['Pregnancy_Count']), np.std(Dataset['Pregnancy_Count'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Pregnancy_Count'] if x < lower or x > upper]\n",
    "print('Pregnancy_Count Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Pregnancy_Count'])):\n",
    "    if Dataset['Pregnancy_Count'][i] < lower:\n",
    "        Dataset['Pregnancy_Count'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Pregnancy_Count'])):\n",
    "    if Dataset['Pregnancy_Count'][i] > upper:\n",
    "        Dataset['Pregnancy_Count'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Pregnancy_Count'] if x < lower or x > upper]\n",
    "print('Pregnancy_Count Column Identified outliers: %d' % len(outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08c2cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= Dataset.loc[:, Dataset.columns != 'Refracture']\n",
    "Y = Dataset[\"Refracture\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a44f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=5)\n",
    "X_balanced, Y_balanced = sm.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df709cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Menopause_age', 'Tscore_Hip_total', 'CRP', 'Cr', 'ALP', 'BUN',\n",
       "       'P', 'Ca', 'PTH', 'Vit_D3', 'BMD_vertebra', 'Tscore_vertebra',\n",
       "       'Zscore_vertebra', 'BMD_Hip_total', 'Zscore_hip_total', 'BMD_Hip_Neck',\n",
       "       'Tscore_Hip_neck', 'Zscore_Hip_neck', 'BMI', 'Pregnancy_Count',\n",
       "       'Histroy_Anticoagulant', 'Active_Smoking', 'History_Smoking',\n",
       "       'Calcium_Supplement', 'History_Diabetes_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dae51c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Menopause_age</th>\n",
       "      <th>Tscore_Hip_total</th>\n",
       "      <th>CRP</th>\n",
       "      <th>Cr</th>\n",
       "      <th>ALP</th>\n",
       "      <th>BUN</th>\n",
       "      <th>P</th>\n",
       "      <th>Ca</th>\n",
       "      <th>PTH</th>\n",
       "      <th>...</th>\n",
       "      <th>BMD_Hip_Neck</th>\n",
       "      <th>Tscore_Hip_neck</th>\n",
       "      <th>Zscore_Hip_neck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pregnancy_Count</th>\n",
       "      <th>Histroy_Anticoagulant</th>\n",
       "      <th>Active_Smoking</th>\n",
       "      <th>History_Smoking</th>\n",
       "      <th>Calcium_Supplement</th>\n",
       "      <th>History_Diabetes_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.196206</td>\n",
       "      <td>0.148641</td>\n",
       "      <td>-0.004757</td>\n",
       "      <td>0.014864</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>0.951300</td>\n",
       "      <td>0.074320</td>\n",
       "      <td>0.013378</td>\n",
       "      <td>0.026458</td>\n",
       "      <td>0.104048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>-0.006837</td>\n",
       "      <td>-0.002378</td>\n",
       "      <td>0.079374</td>\n",
       "      <td>0.030252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.322270</td>\n",
       "      <td>0.247900</td>\n",
       "      <td>-0.012891</td>\n",
       "      <td>0.029748</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>0.842859</td>\n",
       "      <td>0.084286</td>\n",
       "      <td>0.020824</td>\n",
       "      <td>0.044126</td>\n",
       "      <td>0.155681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>-0.017353</td>\n",
       "      <td>-0.009916</td>\n",
       "      <td>0.140311</td>\n",
       "      <td>0.050453</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.330991</td>\n",
       "      <td>0.183884</td>\n",
       "      <td>-0.007815</td>\n",
       "      <td>0.133316</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.873450</td>\n",
       "      <td>0.087345</td>\n",
       "      <td>0.019768</td>\n",
       "      <td>0.040914</td>\n",
       "      <td>0.193078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>-0.013791</td>\n",
       "      <td>-0.005057</td>\n",
       "      <td>0.112169</td>\n",
       "      <td>0.046781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.302979</td>\n",
       "      <td>0.195470</td>\n",
       "      <td>-0.000977</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.855183</td>\n",
       "      <td>0.078188</td>\n",
       "      <td>0.015638</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>0.258998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>-0.007330</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.110441</td>\n",
       "      <td>0.049728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.239590</td>\n",
       "      <td>0.157625</td>\n",
       "      <td>-0.005044</td>\n",
       "      <td>0.040982</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.914223</td>\n",
       "      <td>0.072507</td>\n",
       "      <td>0.010403</td>\n",
       "      <td>0.026796</td>\n",
       "      <td>0.204912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>-0.005674</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.104663</td>\n",
       "      <td>0.031525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Menopause_age  Tscore_Hip_total       CRP        Cr       ALP  \\\n",
       "0  0.196206       0.148641         -0.004757  0.014864  0.003270  0.951300   \n",
       "1  0.322270       0.247900         -0.012891  0.029748  0.003471  0.842859   \n",
       "2  0.330991       0.183884         -0.007815  0.133316  0.003218  0.873450   \n",
       "3  0.302979       0.195470         -0.000977  0.004887  0.004398  0.855183   \n",
       "4  0.239590       0.157625         -0.005044  0.040982  0.003783  0.914223   \n",
       "\n",
       "        BUN         P        Ca       PTH  ...  BMD_Hip_Neck  Tscore_Hip_neck  \\\n",
       "0  0.074320  0.013378  0.026458  0.104048  ...      0.001766        -0.006837   \n",
       "1  0.084286  0.020824  0.044126  0.155681  ...      0.002266        -0.017353   \n",
       "2  0.087345  0.019768  0.040914  0.193078  ...      0.002363        -0.013791   \n",
       "3  0.078188  0.015638  0.043003  0.258998  ...      0.003347        -0.007330   \n",
       "4  0.072507  0.010403  0.026796  0.204912  ...      0.002033        -0.005674   \n",
       "\n",
       "   Zscore_Hip_neck       BMI  Pregnancy_Count  Histroy_Anticoagulant  \\\n",
       "0        -0.002378  0.079374         0.030252                      0   \n",
       "1        -0.009916  0.140311         0.050453                      1   \n",
       "2        -0.005057  0.112169         0.046781                      0   \n",
       "3         0.003421  0.110441         0.049728                      0   \n",
       "4         0.000946  0.104663         0.031525                      0   \n",
       "\n",
       "   Active_Smoking  History_Smoking  Calcium_Supplement  History_Diabetes_2  \n",
       "0               0                0                   0                   0  \n",
       "1               0                0                   0                   0  \n",
       "2               0                0                   0                   0  \n",
       "3               0                0                   0                   0  \n",
       "4               0                0                   0                   0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_balanced[['Age', 'Tscore_Hip_total','CRP',\n",
    "       'Cr', 'ALP', 'BUN',\n",
    "       'P', 'Ca', 'PTH'\n",
    "       ,'Vit_D3', 'BMD_vertebra', 'Tscore_vertebra', 'Zscore_vertebra',\n",
    "        'BMD_Hip_total', 'Zscore_hip_total', 'BMD_Hip_Neck', 'Tscore_Hip_neck',\n",
    "        'Zscore_Hip_neck', 'BMI', 'Menopause_age', 'Pregnancy_Count']] = normalize(X_balanced[['Age', 'Tscore_Hip_total','CRP',\n",
    "       'Cr', 'ALP', 'BUN',\n",
    "       'P', 'Ca', 'PTH'\n",
    "       ,'Vit_D3', 'BMD_vertebra', 'Tscore_vertebra', 'Zscore_vertebra',\n",
    "        'BMD_Hip_total', 'Zscore_hip_total', 'BMD_Hip_Neck', 'Tscore_Hip_neck',\n",
    "        'Zscore_Hip_neck', 'BMI', 'Menopause_age', 'Pregnancy_Count']])\n",
    "X_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2904a281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Menopause_age', 'Tscore_Hip_total', 'CRP', 'Cr', 'ALP', 'BUN',\n",
       "       'P', 'Ca', 'PTH', 'Vit_D3', 'BMD_vertebra', 'Tscore_vertebra',\n",
       "       'Zscore_vertebra', 'BMD_Hip_total', 'Zscore_hip_total', 'BMD_Hip_Neck',\n",
       "       'Tscore_Hip_neck', 'Zscore_Hip_neck', 'BMI', 'Pregnancy_Count',\n",
       "       'Histroy_Anticoagulant', 'Active_Smoking', 'History_Smoking',\n",
       "       'Calcium_Supplement', 'History_Diabetes_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Y_balanced\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04891e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(results):\n",
    "    print(f'Best parameters are: {results.best_params_}')\n",
    "    print(f'Best Score is : {results.best_score_} ')\n",
    "    print(\"\\n\")\n",
    "    mean_score = results.cv_results_['mean_test_score']\n",
    "    std_score = results.cv_results_['std_test_score']\n",
    "    params = results.cv_results_['params']\n",
    "    for mean,std,params in zip(mean_score,std_score,params):\n",
    "        print(f'{round(mean,3)} + or -{round(std,3)} for the {params}')\n",
    "        \n",
    "def showResults(model, modelType , X, Y):\n",
    "    scores_accuracy = cross_val_score(model, X, Y, cv=10, scoring='accuracy')\n",
    "    scores_log_loss = cross_val_score(model, X, Y, cv=10, scoring='neg_log_loss')\n",
    "    scores_briar = cross_val_score(model, X, Y, cv=10, scoring='neg_brier_score')\n",
    "    scores_auc = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\n",
    "    scores_recall = cross_val_score(model, X, Y, cv=10, scoring='recall')\n",
    "    scores_precision = cross_val_score(model, X, Y, cv=10, scoring='precision')\n",
    "    scores_f1 = cross_val_score(model, X, Y, cv=10, scoring='f1')\n",
    "    print('K-fold cross-validation results:')\n",
    "    print(modelType ,\" average accuracy is %2.3f\" % scores_accuracy.mean())\n",
    "    print(modelType ,\" average log_loss is %2.3f\" % -scores_log_loss.mean())\n",
    "    print(modelType ,\" average brier score is %2.3f\" % -scores_briar.mean())\n",
    "    print(modelType ,\" average auc is %2.3f\" % scores_auc.mean())\n",
    "    print(modelType ,\" average recall is %2.3f\" % scores_recall.mean())\n",
    "    print(modelType ,\" average precision is %2.3f\" % scores_precision.mean())\n",
    "    print(modelType ,\" average f1 is %2.3f\" % scores_f1.mean())\n",
    "    \n",
    "params = {\n",
    "    \"max_depth\": [ 3, 4, 6, 8, 10, 15],\n",
    "    'n_estimators': range(100,1000,200),\n",
    "    'learning_rate': [0.1,0.01,0.001],\n",
    "    \"colsample_bytree\" : [0.3, 0.5 , 0.8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c53a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pysician Opinion\n",
    "X = X_balanced[['Age', 'Menopause_age', 'Tscore_Hip_total', 'CRP', 'Cr', 'ALP', 'BUN',\n",
    "       'P', 'Ca', 'PTH', 'Vit_D3', 'BMD_vertebra', 'Tscore_vertebra',\n",
    "       'Zscore_vertebra', 'BMD_Hip_total', 'Zscore_hip_total', 'BMD_Hip_Neck',\n",
    "       'Tscore_Hip_neck', 'Zscore_Hip_neck', 'BMI', 'Pregnancy_Count',\n",
    "       'Histroy_Anticoagulant', 'Active_Smoking', 'History_Smoking',\n",
    "       'Calcium_Supplement', 'History_Diabetes_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92fad6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 270 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_c...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.3, 0.5, 0.8],\n",
       "                         'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': [3, 4, 6, 8, 10, 15],\n",
       "                         'n_estimators': range(100, 1000, 200)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "cv = GridSearchCV(xgb,params,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "723db357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "Best Score is : 0.8073482932996207 \n",
      "\n",
      "\n",
      "0.683 + or -0.099 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.738 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.74 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.751 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.752 + or -0.071 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.724 + or -0.093 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.752 + or -0.081 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.762 + or -0.078 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.771 + or -0.069 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.779 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.759 + or -0.081 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.77 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.775 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.774 + or -0.077 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.778 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.782 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.798 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.798 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.795 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.797 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.791 + or -0.065 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.789 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.787 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.791 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.794 + or -0.065 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.785 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.782 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.785 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.784 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.784 + or -0.067 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.656 + or -0.093 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.665 + or -0.096 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.68 + or -0.092 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.672 + or -0.1 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.688 + or -0.098 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.679 + or -0.092 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.699 + or -0.093 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.712 + or -0.092 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.719 + or -0.085 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.72 + or -0.082 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.728 + or -0.078 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.745 + or -0.085 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.755 + or -0.08 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.764 + or -0.087 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.767 + or -0.091 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.759 + or -0.076 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.784 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.791 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.795 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.798 + or -0.069 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.775 + or -0.078 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.796 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.806 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.806 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.803 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.78 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.794 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.801 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.806 + or -0.065 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.804 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.659 + or -0.098 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.672 + or -0.082 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.664 + or -0.086 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.664 + or -0.092 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.664 + or -0.095 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.686 + or -0.082 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.684 + or -0.076 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.685 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.68 + or -0.086 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.681 + or -0.092 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.719 + or -0.076 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.731 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.731 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.734 + or -0.08 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.733 + or -0.084 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.757 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.772 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.77 + or -0.065 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.77 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.775 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.771 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.783 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.795 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.798 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.797 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.78 + or -0.069 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.793 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.804 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.807 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.806 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.676 + or -0.086 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.73 + or -0.085 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.752 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.768 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.765 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.723 + or -0.094 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.766 + or -0.095 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.769 + or -0.087 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.777 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.782 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.767 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.787 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.794 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.79 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.792 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.787 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.797 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.798 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.8 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.8 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.791 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.802 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.805 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.805 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.806 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.795 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.802 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.798 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.796 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.796 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.645 + or -0.096 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.656 + or -0.089 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.671 + or -0.087 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.674 + or -0.09 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.678 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.68 + or -0.087 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.689 + or -0.098 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.704 + or -0.099 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.713 + or -0.098 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.718 + or -0.096 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.727 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.732 + or -0.094 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.751 + or -0.088 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.753 + or -0.091 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.756 + or -0.089 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.781 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.786 + or -0.092 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.786 + or -0.087 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.79 + or -0.088 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.794 + or -0.081 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.787 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.8 + or -0.086 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.795 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.797 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.796 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.794 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.793 + or -0.082 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.794 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.79 + or -0.081 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.79 + or -0.081 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.655 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.656 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.654 + or -0.086 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.656 + or -0.09 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.652 + or -0.092 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.688 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.68 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.684 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.684 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.682 + or -0.081 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.726 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.735 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.739 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.738 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.736 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.763 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.768 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.77 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.773 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.773 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.779 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.786 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.784 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.789 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.788 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.782 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.793 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.794 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.797 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.797 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.685 + or -0.091 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.731 + or -0.082 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.746 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.762 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.767 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.73 + or -0.091 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.774 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.784 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.787 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.785 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.756 + or -0.083 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.781 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.787 + or -0.086 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.787 + or -0.082 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.786 + or -0.083 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.78 + or -0.07 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.797 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.794 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.791 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.796 + or -0.082 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.797 + or -0.092 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.804 + or -0.081 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.798 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.8 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.804 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.79 + or -0.082 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.798 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.798 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.802 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.797 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.632 + or -0.095 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.656 + or -0.098 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.67 + or -0.092 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.679 + or -0.092 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.684 + or -0.087 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.664 + or -0.095 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.686 + or -0.094 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.705 + or -0.098 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.711 + or -0.1 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.714 + or -0.101 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.71 + or -0.089 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.727 + or -0.102 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.74 + or -0.096 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.752 + or -0.092 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.761 + or -0.086 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.746 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.752 + or -0.091 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.761 + or -0.098 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.773 + or -0.097 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.782 + or -0.094 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.751 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.757 + or -0.108 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.778 + or -0.096 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.785 + or -0.097 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.79 + or -0.095 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.765 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.774 + or -0.096 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.776 + or -0.103 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.787 + or -0.102 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.788 + or -0.093 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.629 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.64 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.649 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.641 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.632 + or -0.087 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.657 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.681 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.68 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.66 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.656 + or -0.098 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.715 + or -0.039 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.723 + or -0.036 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.717 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.71 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.704 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.749 + or -0.036 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.745 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.755 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.748 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.741 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.761 + or -0.038 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.768 + or -0.038 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.764 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.766 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.768 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.762 + or -0.036 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.774 + or -0.035 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.77 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.773 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.775 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82fac922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "XGBoost  average accuracy is 0.807\n",
      "XGBoost  average log_loss is 0.604\n",
      "XGBoost  average brier score is 0.206\n",
      "XGBoost  average auc is 0.888\n",
      "XGBoost  average recall is 0.838\n",
      "XGBoost  average precision is 0.793\n",
      "XGBoost  average f1 is 0.813\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42, n_estimators=700,\n",
    "                   max_depth = 15, learning_rate = 0.001, colsample_bytree = 0.3)\n",
    "xgb.fit(X,Y)\n",
    "\n",
    "showResults(xgb, \"XGBoost\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0319961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV + Random Forest\n",
    "X = X_balanced[['Age', 'Menopause_age', 'Tscore_Hip_total', 'CRP', 'Cr', 'ALP', 'BUN', 'P', \n",
    "                'Ca', 'PTH', 'Vit_D3', 'Tscore_vertebra', 'Zscore_vertebra', 'BMD_Hip_total', \n",
    "                'Zscore_hip_total', 'BMD_Hip_Neck', 'Zscore_Hip_neck', 'BMI', 'Pregnancy_Count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a72f5e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 270 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_c...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.3, 0.5, 0.8],\n",
       "                         'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': [3, 4, 6, 8, 10, 15],\n",
       "                         'n_estimators': range(100, 1000, 200)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "cv = GridSearchCV(xgb,params,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a168b555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "Best Score is : 0.8232695954487991 \n",
      "\n",
      "\n",
      "0.679 + or -0.106 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.738 + or -0.082 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.748 + or -0.079 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.752 + or -0.076 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.755 + or -0.079 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.733 + or -0.096 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.757 + or -0.092 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.77 + or -0.09 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.777 + or -0.086 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.779 + or -0.083 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.769 + or -0.09 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.791 + or -0.084 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.792 + or -0.086 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.795 + or -0.086 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.796 + or -0.085 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.795 + or -0.065 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.807 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.798 + or -0.069 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.798 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.797 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.796 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.792 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.794 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.795 + or -0.076 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.792 + or -0.078 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.782 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.795 + or -0.071 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.79 + or -0.079 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.79 + or -0.077 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.79 + or -0.081 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.641 + or -0.111 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.664 + or -0.102 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.676 + or -0.089 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.681 + or -0.09 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.686 + or -0.097 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.674 + or -0.102 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.697 + or -0.089 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.706 + or -0.096 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.711 + or -0.091 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.719 + or -0.093 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.724 + or -0.088 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.744 + or -0.101 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.764 + or -0.09 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.774 + or -0.088 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.78 + or -0.091 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.756 + or -0.086 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.784 + or -0.083 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.8 + or -0.08 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.799 + or -0.083 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.799 + or -0.083 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.775 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.801 + or -0.077 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.806 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.815 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.806 + or -0.076 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.787 + or -0.081 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.799 + or -0.08 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.805 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.811 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.808 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.632 + or -0.1 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.638 + or -0.101 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.648 + or -0.102 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.654 + or -0.105 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.651 + or -0.101 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.665 + or -0.104 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.671 + or -0.095 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.678 + or -0.088 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.682 + or -0.088 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.688 + or -0.094 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.707 + or -0.09 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.712 + or -0.084 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.722 + or -0.077 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.735 + or -0.083 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.74 + or -0.087 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.739 + or -0.077 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.751 + or -0.08 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.762 + or -0.077 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.77 + or -0.078 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.774 + or -0.079 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.759 + or -0.076 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.772 + or -0.08 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.785 + or -0.078 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.789 + or -0.079 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.794 + or -0.078 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.773 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.783 + or -0.079 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.796 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.794 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.805 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.705 + or -0.086 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.75 + or -0.089 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.768 + or -0.082 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.775 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.781 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.753 + or -0.091 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.788 + or -0.082 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.796 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.797 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.794 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.781 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.798 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.797 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.8 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.797 + or -0.065 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.799 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.803 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.804 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.805 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.8 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.806 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.81 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.809 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.806 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.809 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.802 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.803 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.798 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.798 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.798 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.643 + or -0.092 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.67 + or -0.096 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.677 + or -0.081 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.68 + or -0.085 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.696 + or -0.085 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.687 + or -0.098 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.704 + or -0.088 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.721 + or -0.087 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.726 + or -0.085 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.735 + or -0.091 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.743 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.76 + or -0.092 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.764 + or -0.092 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.772 + or -0.096 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.778 + or -0.082 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.777 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.783 + or -0.081 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.794 + or -0.085 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.796 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.798 + or -0.081 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.793 + or -0.082 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.798 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.796 + or -0.088 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.798 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.801 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.807 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.808 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.806 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.808 + or -0.085 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.807 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.645 + or -0.085 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.643 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.641 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.643 + or -0.092 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.642 + or -0.092 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.681 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.685 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.691 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.687 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.687 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.732 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.734 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.743 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.747 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.751 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.768 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.774 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.782 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.782 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.784 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.782 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.79 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.8 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.797 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.796 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.79 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.8 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.807 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.808 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.809 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.704 + or -0.081 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.773 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.784 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.792 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.798 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.76 + or -0.081 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.794 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.806 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.805 + or -0.07 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.806 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.802 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.821 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.822 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.821 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.821 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.805 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.821 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.823 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.818 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.82 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.801 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.811 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.817 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.81 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.811 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.805 + or -0.083 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.818 + or -0.083 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.816 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.819 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.816 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.629 + or -0.083 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.659 + or -0.084 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.687 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.695 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.705 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.665 + or -0.102 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.702 + or -0.083 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.718 + or -0.084 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.726 + or -0.081 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.737 + or -0.081 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.724 + or -0.082 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.761 + or -0.082 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.775 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.783 + or -0.081 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.788 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.761 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.778 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.793 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.798 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.805 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.774 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.789 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.806 + or -0.087 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.809 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.815 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.79 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.802 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.805 + or -0.081 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.812 + or -0.082 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.815 + or -0.086 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.631 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.627 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.63 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.631 + or -0.093 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.639 + or -0.088 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.671 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.678 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.676 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.676 + or -0.088 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.673 + or -0.085 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.719 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.719 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.724 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.719 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.721 + or -0.088 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.738 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.752 + or -0.039 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.754 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.752 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.75 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.752 + or -0.042 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.761 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.767 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.775 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.775 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.752 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.765 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.778 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.779 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.784 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9af5b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "XGBoost  average accuracy is 0.823\n",
      "XGBoost  average log_loss is 0.445\n",
      "XGBoost  average brier score is 0.135\n",
      "XGBoost  average auc is 0.905\n",
      "XGBoost  average recall is 0.908\n",
      "XGBoost  average precision is 0.782\n",
      "XGBoost  average f1 is 0.839\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42, n_estimators=500,\n",
    "                   max_depth = 8, learning_rate = 0.1, colsample_bytree = 0.8)\n",
    "xgb.fit(X,Y)\n",
    "\n",
    "showResults(xgb, \"XGBoost\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc84b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV + XGBoost\n",
    "X = X_balanced[['Age', 'Menopause_age', 'CRP', 'Cr', 'ALP', 'BUN', 'P', 'Ca', 'PTH', \n",
    "                'BMD_Hip_Neck', 'Zscore_Hip_neck', 'Pregnancy_Count', 'Histroy_Anticoagulant', \n",
    "                'History_Smoking', 'History_Diabetes_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa51ef3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 270 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_c...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.3, 0.5, 0.8],\n",
       "                         'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': [3, 4, 6, 8, 10, 15],\n",
       "                         'n_estimators': range(100, 1000, 200)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "cv = GridSearchCV(xgb,params,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ceec9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "Best Score is : 0.8179756637168142 \n",
      "\n",
      "\n",
      "0.684 + or -0.087 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.72 + or -0.077 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.727 + or -0.083 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.736 + or -0.081 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.743 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.714 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.746 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.753 + or -0.083 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.759 + or -0.076 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.764 + or -0.077 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.75 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.772 + or -0.082 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.773 + or -0.081 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.773 + or -0.08 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.769 + or -0.076 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.761 + or -0.067 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.772 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.771 + or -0.078 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.779 + or -0.071 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.782 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.773 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.777 + or -0.067 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.78 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.782 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.785 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.783 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.786 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.788 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.785 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.784 + or -0.067 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.663 + or -0.09 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.685 + or -0.092 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.692 + or -0.095 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.695 + or -0.095 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.699 + or -0.1 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.688 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.711 + or -0.078 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.717 + or -0.079 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.724 + or -0.085 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.726 + or -0.084 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.726 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.75 + or -0.076 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.759 + or -0.078 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.764 + or -0.077 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.766 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.766 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.774 + or -0.077 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.789 + or -0.078 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.785 + or -0.083 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.79 + or -0.079 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.767 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.794 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.798 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.8 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.798 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.783 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.801 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.798 + or -0.071 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.805 + or -0.065 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.8 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.655 + or -0.088 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.653 + or -0.089 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.657 + or -0.093 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.675 + or -0.086 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.671 + or -0.092 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.678 + or -0.084 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.692 + or -0.087 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.687 + or -0.091 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.688 + or -0.086 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.693 + or -0.09 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.719 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.736 + or -0.082 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.735 + or -0.082 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.727 + or -0.08 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.732 + or -0.08 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.759 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.762 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.759 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.764 + or -0.069 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.762 + or -0.067 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.775 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.782 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.777 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.776 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.782 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.774 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.788 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.782 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.782 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.787 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.691 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.745 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.756 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.763 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.767 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.733 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.76 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.768 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.773 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.78 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.77 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.784 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.785 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.784 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.789 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.794 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.795 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.794 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.794 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.801 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.79 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.802 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.803 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.8 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.797 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.792 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.798 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.801 + or -0.065 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.805 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.805 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.662 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.676 + or -0.089 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.689 + or -0.086 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.694 + or -0.087 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.7 + or -0.089 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.692 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.712 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.728 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.732 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.736 + or -0.089 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.748 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.751 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.759 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.766 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.771 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.775 + or -0.065 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.78 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.786 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.789 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.791 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.798 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.805 + or -0.081 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.803 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.805 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.803 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.799 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.807 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.809 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.809 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.806 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.657 + or -0.082 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.659 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.664 + or -0.082 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.668 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.665 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.686 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.695 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.692 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.692 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.701 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.737 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.743 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.748 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.751 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.753 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.774 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.775 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.778 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.776 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.776 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.796 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.803 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.798 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.798 + or -0.065 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.795 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.805 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.809 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.81 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.806 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.805 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.71 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.755 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.752 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.762 + or -0.07 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.773 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.747 + or -0.082 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.767 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.778 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.783 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.788 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.774 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.786 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.789 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.795 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.794 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.794 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.798 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.799 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.8 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.8 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.804 + or -0.07 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.809 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.804 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.807 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.81 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.81 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.818 + or -0.07 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.813 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.812 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.812 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.646 + or -0.081 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.668 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.686 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.696 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.696 + or -0.082 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.677 + or -0.092 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.708 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.726 + or -0.085 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.735 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.748 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.724 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.751 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.764 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.767 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.774 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.769 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.772 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.782 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.785 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.789 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.794 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.791 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.796 + or -0.07 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.797 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.801 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.791 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.791 + or -0.086 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.802 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.796 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.799 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.65 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.64 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.653 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.65 + or -0.081 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.643 + or -0.084 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.671 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.671 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.686 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.679 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.673 + or -0.093 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.71 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.723 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.722 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.723 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.72 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.746 + or -0.042 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.742 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.763 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.768 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.777 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.762 + or -0.04 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.767 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.783 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.784 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.788 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.771 + or -0.04 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.775 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.788 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.795 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.797 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d0f67bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "XGBoost  average accuracy is 0.818\n",
      "XGBoost  average log_loss is 0.460\n",
      "XGBoost  average brier score is 0.139\n",
      "XGBoost  average auc is 0.891\n",
      "XGBoost  average recall is 0.886\n",
      "XGBoost  average precision is 0.784\n",
      "XGBoost  average f1 is 0.830\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42, n_estimators=300,\n",
    "                   max_depth = 15, learning_rate = 0.1, colsample_bytree = 0.8)\n",
    "xgb.fit(X,Y)\n",
    "\n",
    "showResults(xgb, \"XGBoost\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0c5fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV + CatBoost\n",
    "X = X_balanced[['Age', 'Menopause_age', 'Tscore_Hip_total', 'CRP', 'Cr', 'ALP', 'BUN', 'P', \n",
    "                'Ca', 'PTH', 'Vit_D3', 'BMD_vertebra', 'Tscore_vertebra', 'Zscore_vertebra', \n",
    "                'BMD_Hip_total', 'Zscore_hip_total', 'BMD_Hip_Neck', 'Zscore_Hip_neck', 'BMI', \n",
    "                'Pregnancy_Count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a983e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 270 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_c...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.3, 0.5, 0.8],\n",
       "                         'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': [3, 4, 6, 8, 10, 15],\n",
       "                         'n_estimators': range(100, 1000, 200)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "cv = GridSearchCV(xgb,params,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f625e5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "Best Score is : 0.8224004424778762 \n",
      "\n",
      "\n",
      "0.693 + or -0.096 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.735 + or -0.091 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.747 + or -0.085 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.757 + or -0.079 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.76 + or -0.069 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.731 + or -0.084 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.772 + or -0.079 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.778 + or -0.077 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.783 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.789 + or -0.076 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.787 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.791 + or -0.077 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.79 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.79 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.79 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.808 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.801 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.794 + or -0.065 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.797 + or -0.065 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.801 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.808 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.814 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.81 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.809 + or -0.069 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.81 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.822 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.807 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.802 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.804 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.802 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.656 + or -0.09 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.661 + or -0.101 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.678 + or -0.096 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.688 + or -0.1 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.696 + or -0.095 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.693 + or -0.087 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.696 + or -0.091 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.711 + or -0.095 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.716 + or -0.09 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.729 + or -0.097 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.742 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.757 + or -0.092 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.767 + or -0.092 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.772 + or -0.094 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.78 + or -0.092 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.782 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.784 + or -0.083 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.798 + or -0.082 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.8 + or -0.079 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.799 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.792 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.808 + or -0.083 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.814 + or -0.079 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.816 + or -0.077 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.816 + or -0.074 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.81 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.813 + or -0.08 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.814 + or -0.077 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.815 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.812 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.647 + or -0.082 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.648 + or -0.09 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.648 + or -0.096 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.655 + or -0.096 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.65 + or -0.098 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.673 + or -0.08 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.678 + or -0.086 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.677 + or -0.094 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.681 + or -0.095 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.687 + or -0.087 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.747 + or -0.071 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.729 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.734 + or -0.085 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.74 + or -0.082 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.743 + or -0.082 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.776 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.774 + or -0.079 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.775 + or -0.079 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.776 + or -0.079 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.78 + or -0.084 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.798 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.794 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.792 + or -0.083 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.794 + or -0.086 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.8 + or -0.081 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.81 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.806 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.809 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.81 + or -0.078 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.811 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.703 + or -0.088 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.748 + or -0.082 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.758 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.766 + or -0.082 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.777 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.736 + or -0.089 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.777 + or -0.087 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.793 + or -0.088 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.792 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.794 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.791 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.804 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.803 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.804 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.805 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.808 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.815 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.813 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.819 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.82 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.806 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.816 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.812 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.813 + or -0.082 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.814 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.811 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.818 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.813 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.81 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.814 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.638 + or -0.09 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.668 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.677 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.691 + or -0.082 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.697 + or -0.086 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.681 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.701 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.719 + or -0.092 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.721 + or -0.091 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.73 + or -0.092 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.741 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.756 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.771 + or -0.092 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.783 + or -0.087 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.788 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.78 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.786 + or -0.09 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.798 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.799 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.798 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.795 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.804 + or -0.091 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.802 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.81 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.808 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.808 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.807 + or -0.087 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.806 + or -0.081 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.807 + or -0.082 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.812 + or -0.086 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.643 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.639 + or -0.082 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.64 + or -0.081 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.638 + or -0.086 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.641 + or -0.088 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.679 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.677 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.684 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.687 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.687 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.728 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.736 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.741 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.746 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.743 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.765 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.766 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.774 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.782 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.779 + or -0.085 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.782 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.785 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.789 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.791 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.791 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.791 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.795 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.798 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.801 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.806 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.696 + or -0.087 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.765 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.784 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.787 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.791 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.742 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.785 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.797 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.798 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.802 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.796 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.809 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.812 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.804 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.807 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.797 + or -0.081 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.812 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.813 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.808 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.81 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.796 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.806 + or -0.083 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.805 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.807 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.81 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.792 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.81 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.805 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.805 + or -0.081 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.807 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.638 + or -0.086 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.66 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.684 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.693 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.7 + or -0.083 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.669 + or -0.086 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.697 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.723 + or -0.082 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.733 + or -0.09 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.742 + or -0.093 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.715 + or -0.088 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.752 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.767 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.784 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.789 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.748 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.775 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.798 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.798 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.798 + or -0.081 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.768 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.794 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.807 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.809 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.808 + or -0.086 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.78 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.787 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.799 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.808 + or -0.084 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.81 + or -0.084 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.629 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.622 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.629 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.628 + or -0.094 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.636 + or -0.086 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.669 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.675 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.67 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.673 + or -0.09 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.672 + or -0.09 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.713 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.719 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.713 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.719 + or -0.077 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.716 + or -0.086 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.736 + or -0.037 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.754 + or -0.038 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.752 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.755 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.759 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.759 + or -0.037 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.766 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.769 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.767 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.773 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.758 + or -0.042 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.769 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.78 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.78 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.777 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdeb26d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "XGBoost  average accuracy is 0.822\n",
      "XGBoost  average log_loss is 0.406\n",
      "XGBoost  average brier score is 0.130\n",
      "XGBoost  average auc is 0.906\n",
      "XGBoost  average recall is 0.877\n",
      "XGBoost  average precision is 0.795\n",
      "XGBoost  average f1 is 0.833\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42, n_estimators=100,\n",
    "                   max_depth = 15, learning_rate = 0.1, colsample_bytree = 0.3)\n",
    "xgb.fit(X,Y)\n",
    "\n",
    "showResults(xgb, \"XGBoost\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40998df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X,Y, test_size=0.2, random_state=5)\n",
    "calibrated = CalibratedClassifierCV(xgb, method='sigmoid', cv=10)\n",
    "calibrated.fit(xtrain, ytrain)\n",
    "probs = calibrated.predict_proba(xtest)[:, 1]\n",
    "uncalibrated = xgb.predict_proba(xtest)[:,1]\n",
    "fop_uncalibrated, mpv_uncalibrated = calibration_curve(ytest, uncalibrated, n_bins=10, normalize=True)\n",
    "fop_calibrated, mpv_calibrated = calibration_curve(ytest, probs, n_bins=10, normalize=True)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label = 'Ideally Calibrated')\n",
    "plt.plot(mpv_uncalibrated, fop_uncalibrated, marker='.', label = 'XGBoost Uncalibrated')\n",
    "plt.plot(mpv_calibrated, fop_calibrated, marker='.', label = 'XGBoost Calibrated')\n",
    "leg = plt.legend(loc = 'upper left')\n",
    "plt.xlabel('Average Predicted Probability in each bin')\n",
    "plt.ylabel('Ratio of positives')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2269a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "XGBoost average accuracy is 0.817\n",
      "XGBoost average log_loss is 0.407\n",
      "XGBoost average brier score is 0.127\n",
      "XGBoost average auc is 0.906\n",
      "XGBoost average recall is 0.838\n",
      "XGBoost average precision is 0.809\n",
      "XGBoost average f1 is 0.822\n"
     ]
    }
   ],
   "source": [
    "calibrated = CalibratedClassifierCV(xgb, method='sigmoid', cv=10)\n",
    "\n",
    "scores_accuracy = cross_val_score(calibrated, X, Y, cv=10, scoring='accuracy')\n",
    "scores_log_loss = cross_val_score(calibrated, X, Y, cv=10, scoring='neg_log_loss')\n",
    "scores_briar = cross_val_score(calibrated, X, Y, cv=10, scoring='neg_brier_score')\n",
    "scores_auc = cross_val_score(calibrated, X, Y, cv=10, scoring='roc_auc')\n",
    "scores_recall = cross_val_score(calibrated, X, Y, cv=10, scoring='recall')\n",
    "scores_precision = cross_val_score(calibrated, X, Y, cv=10, scoring='precision')\n",
    "scores_f1 = cross_val_score(calibrated, X, Y, cv=10, scoring='f1')\n",
    "print('K-fold cross-validation results:')\n",
    "print(\"XGBoost average accuracy is %2.3f\" % scores_accuracy.mean())\n",
    "print(\"XGBoost average log_loss is %2.3f\" % -scores_log_loss.mean())\n",
    "print(\"XGBoost average brier score is %2.3f\" % -scores_briar.mean())\n",
    "print(\"XGBoost average auc is %2.3f\" % scores_auc.mean())\n",
    "print(\"XGBoost average recall is %2.3f\" % scores_recall.mean())\n",
    "print(\"XGBoost average precision is %2.3f\" % scores_precision.mean())\n",
    "print(\"XGBoost average f1 is %2.3f\" % scores_f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56bd524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV + Logistic Regression\n",
    "X = X_balanced[['Cr', 'BMD_Hip_total', 'Histroy_Anticoagulant', 'History_Smoking']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1f0dd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 270 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_c...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.3, 0.5, 0.8],\n",
       "                         'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': [3, 4, 6, 8, 10, 15],\n",
       "                         'n_estimators': range(100, 1000, 200)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "cv = GridSearchCV(xgb,params,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb962820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "Best Score is : 0.6074352085967131 \n",
      "\n",
      "\n",
      "0.575 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.572 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.575 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.565 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.557 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.567 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.555 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.554 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.551 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.555 + or -0.031 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.563 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.557 + or -0.033 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.549 + or -0.029 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.55 + or -0.029 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.545 + or -0.03 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.551 + or -0.03 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.544 + or -0.028 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.552 + or -0.032 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.547 + or -0.031 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.543 + or -0.025 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.555 + or -0.032 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.549 + or -0.031 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.55 + or -0.027 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.548 + or -0.032 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.545 + or -0.028 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.543 + or -0.04 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.551 + or -0.034 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.544 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.543 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.538 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.576 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.567 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.572 + or -0.065 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.58 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.568 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.568 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.579 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.576 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.563 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.565 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.553 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.551 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.552 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.556 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.548 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.559 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.553 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.552 + or -0.035 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.556 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.554 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.554 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.551 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.553 + or -0.04 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.546 + or -0.028 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.546 + or -0.035 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.561 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.553 + or -0.04 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.554 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.551 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.549 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.569 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.568 + or -0.069 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.567 + or -0.067 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.571 + or -0.069 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.575 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.574 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.572 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.572 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.572 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.578 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.553 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.559 + or -0.055 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.56 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.564 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.564 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.555 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.553 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.552 + or -0.052 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.551 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.558 + or -0.067 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.544 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.547 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.553 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.553 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.552 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.565 + or -0.03 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.561 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.558 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.555 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.558 + or -0.04 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.602 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.59 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.575 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.563 + or -0.037 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.572 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.582 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.555 + or -0.024 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.556 + or -0.024 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.559 + or -0.024 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.563 + or -0.024 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.577 + or -0.036 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.566 + or -0.034 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.559 + or -0.038 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.566 + or -0.025 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.571 + or -0.021 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.568 + or -0.045 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.567 + or -0.03 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.57 + or -0.034 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.565 + or -0.026 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.571 + or -0.029 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.577 + or -0.032 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.573 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.569 + or -0.031 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.567 + or -0.032 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.569 + or -0.029 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.569 + or -0.028 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.571 + or -0.022 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.573 + or -0.022 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.572 + or -0.018 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.571 + or -0.023 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.573 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.569 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.572 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.583 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.593 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.58 + or -0.065 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.59 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.591 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.584 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.584 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.571 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.581 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.585 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.579 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.575 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.558 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.568 + or -0.038 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.574 + or -0.022 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.572 + or -0.028 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.578 + or -0.028 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.571 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.569 + or -0.028 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.568 + or -0.021 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.57 + or -0.023 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.572 + or -0.024 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.564 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.566 + or -0.039 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.568 + or -0.023 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.568 + or -0.026 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.572 + or -0.03 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.564 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.567 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.567 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.572 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.57 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.571 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.578 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.579 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.582 + or -0.065 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.581 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.575 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.575 + or -0.06 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.567 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.567 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.578 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.559 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.556 + or -0.065 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.557 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.556 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.557 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.563 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.563 + or -0.043 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.568 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.562 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.564 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.569 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.563 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.561 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.564 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.567 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.587 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.596 + or -0.04 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.574 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.566 + or -0.034 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.57 + or -0.036 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.576 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.587 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.591 + or -0.036 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.581 + or -0.036 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.58 + or -0.036 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.598 + or -0.042 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.583 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.589 + or -0.035 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.585 + or -0.03 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.589 + or -0.027 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.579 + or -0.034 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.589 + or -0.039 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.583 + or -0.028 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.592 + or -0.03 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.592 + or -0.031 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.595 + or -0.02 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.594 + or -0.026 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.59 + or -0.034 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.588 + or -0.032 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.588 + or -0.034 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.578 + or -0.033 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.584 + or -0.037 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.582 + or -0.035 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.578 + or -0.032 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.583 + or -0.035 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.582 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.579 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.583 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.584 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.583 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.584 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.585 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.583 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.59 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.588 + or -0.05 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.585 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.589 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.596 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.602 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.607 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.563 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.592 + or -0.035 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.599 + or -0.036 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.592 + or -0.03 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.584 + or -0.028 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.572 + or -0.029 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.586 + or -0.03 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.582 + or -0.028 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.581 + or -0.034 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.58 + or -0.03 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.573 + or -0.039 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.581 + or -0.037 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.581 + or -0.036 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.585 + or -0.036 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.584 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.578 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.593 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.592 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.594 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.59 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.582 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.597 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.585 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.583 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.584 + or -0.056 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.582 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.579 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.575 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.582 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.578 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.567 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.567 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.565 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.56 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.572 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.563 + or -0.035 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.56 + or -0.035 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.563 + or -0.023 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.572 + or -0.025 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.573 + or -0.028 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.568 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.563 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.574 + or -0.036 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.574 + or -0.038 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.572 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6591abb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "XGBoost  average accuracy is 0.607\n",
      "XGBoost  average log_loss is 0.679\n",
      "XGBoost  average brier score is 0.240\n",
      "XGBoost  average auc is 0.645\n",
      "XGBoost  average recall is 0.636\n",
      "XGBoost  average precision is 0.603\n",
      "XGBoost  average f1 is 0.618\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42, n_estimators=900,\n",
    "                   max_depth = 6, learning_rate = 0.01, colsample_bytree = 0.8)\n",
    "xgb.fit(X,Y)\n",
    "\n",
    "showResults(xgb, \"XGBoost\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cc78081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV + LightGBM\n",
    "X = X_balanced[['Menopause_age', 'CRP', 'ALP', 'Ca', 'BMD_Hip_Neck', 'BMI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ae536ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 270 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_c...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.3, 0.5, 0.8],\n",
       "                         'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': [3, 4, 6, 8, 10, 15],\n",
       "                         'n_estimators': range(100, 1000, 200)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "cv = GridSearchCV(xgb,params,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b7813f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "Best Score is : 0.7692082806573957 \n",
      "\n",
      "\n",
      "0.6 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.602 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.602 + or -0.031 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.599 + or -0.035 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.602 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.599 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.593 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.598 + or -0.03 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.593 + or -0.03 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.585 + or -0.035 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.579 + or -0.034 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.573 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.576 + or -0.029 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.571 + or -0.035 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.567 + or -0.028 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.577 + or -0.023 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.578 + or -0.031 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.579 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.578 + or -0.04 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.571 + or -0.04 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.569 + or -0.023 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.575 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.582 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.575 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.574 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.568 + or -0.025 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.567 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.576 + or -0.035 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.576 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.576 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.585 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.597 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.602 + or -0.045 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.6 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.602 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.598 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.595 + or -0.028 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.602 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.592 + or -0.044 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.591 + or -0.048 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.593 + or -0.034 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.58 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.589 + or -0.03 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.591 + or -0.028 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.583 + or -0.021 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.601 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.572 + or -0.035 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.575 + or -0.026 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.576 + or -0.022 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.578 + or -0.026 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.591 + or -0.032 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.57 + or -0.033 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.577 + or -0.035 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.569 + or -0.017 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.567 + or -0.024 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.59 + or -0.03 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.578 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.582 + or -0.028 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.573 + or -0.033 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.57 + or -0.032 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.577 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.583 + or -0.04 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.584 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.589 + or -0.036 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.591 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.62 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.602 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.602 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.599 + or -0.03 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.588 + or -0.04 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.608 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.6 + or -0.043 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.596 + or -0.047 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.595 + or -0.035 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.589 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.607 + or -0.038 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.592 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.588 + or -0.04 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.587 + or -0.051 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.589 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.596 + or -0.034 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.59 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.588 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.578 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.573 + or -0.04 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.599 + or -0.037 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.585 + or -0.041 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.59 + or -0.034 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.584 + or -0.039 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.589 + or -0.04 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.657 + or -0.031 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.687 + or -0.038 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.705 + or -0.03 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.708 + or -0.033 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.703 + or -0.03 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.683 + or -0.036 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.721 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.726 + or -0.042 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.723 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.727 + or -0.034 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.716 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.725 + or -0.033 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.732 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.735 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.739 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.742 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.75 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.751 + or -0.039 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.747 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.749 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.754 + or -0.039 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.746 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.749 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.746 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.745 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.753 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.755 + or -0.035 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.755 + or -0.038 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.752 + or -0.038 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.751 + or -0.039 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.612 + or -0.036 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.637 + or -0.034 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.646 + or -0.029 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.653 + or -0.036 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.662 + or -0.034 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.624 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.663 + or -0.038 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.677 + or -0.037 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.684 + or -0.031 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.694 + or -0.031 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.683 + or -0.037 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.696 + or -0.035 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.704 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.711 + or -0.043 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.717 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.718 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.739 + or -0.035 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.738 + or -0.032 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.746 + or -0.037 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.743 + or -0.043 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.737 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.762 + or -0.043 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.766 + or -0.042 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.754 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.753 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.746 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.762 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.764 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.768 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.766 + or -0.05 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.599 + or -0.036 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.606 + or -0.035 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.606 + or -0.039 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.614 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.623 + or -0.036 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.621 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.616 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.631 + or -0.043 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.631 + or -0.04 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.63 + or -0.036 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.676 + or -0.041 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.674 + or -0.037 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.664 + or -0.033 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.663 + or -0.032 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.665 + or -0.033 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.704 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.715 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.718 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.714 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.717 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.733 + or -0.044 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.739 + or -0.046 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.733 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.739 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.734 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.737 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.738 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.742 + or -0.061 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.746 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.754 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.674 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.707 + or -0.035 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.725 + or -0.036 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.719 + or -0.03 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.721 + or -0.031 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.68 + or -0.038 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.712 + or -0.029 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.72 + or -0.028 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.723 + or -0.037 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.725 + or -0.038 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.72 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.74 + or -0.042 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.74 + or -0.038 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.743 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.736 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.75 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.757 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.755 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.752 + or -0.039 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.754 + or -0.036 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.754 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.76 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.765 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.758 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.755 + or -0.04 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.761 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.761 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.757 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.757 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.761 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.614 + or -0.033 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.633 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.655 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.665 + or -0.04 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.669 + or -0.035 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.626 + or -0.042 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.671 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.686 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.695 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.703 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.671 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.719 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.721 + or -0.042 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.724 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.735 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.725 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.738 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.732 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.74 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.743 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.734 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.747 + or -0.042 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.75 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.751 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.757 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.75 + or -0.042 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.756 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.764 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.769 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.768 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.607 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.61 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.617 + or -0.055 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.618 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.608 + or -0.03 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.617 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.623 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.62 + or -0.039 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.622 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.628 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.662 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.669 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.668 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.663 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.679 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.711 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.711 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.715 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.721 + or -0.045 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.721 + or -0.042 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.722 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.727 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.73 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.732 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.734 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.729 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.727 + or -0.048 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.734 + or -0.043 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.739 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.744 + or -0.041 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2df24c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "XGBoost  average accuracy is 0.769\n",
      "XGBoost  average log_loss is 0.496\n",
      "XGBoost  average brier score is 0.162\n",
      "XGBoost  average auc is 0.843\n",
      "XGBoost  average recall is 0.798\n",
      "XGBoost  average precision is 0.756\n",
      "XGBoost  average f1 is 0.775\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42, n_estimators=700,\n",
    "                   max_depth = 15, learning_rate = 0.01, colsample_bytree = 0.8)\n",
    "xgb.fit(X,Y)\n",
    "\n",
    "showResults(xgb, \"XGBoost\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b3e2a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV + ADABoost\n",
    "X = X_balanced[['Age', 'Menopause_age', 'Cr', 'ALP', 'Ca', 'Vit_D3', 'Tscore_vertebra', \n",
    "                'BMD_Hip_Neck', 'Pregnancy_Count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4490bc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 270 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_c...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.3, 0.5, 0.8],\n",
       "                         'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': [3, 4, 6, 8, 10, 15],\n",
       "                         'n_estimators': range(100, 1000, 200)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "cv = GridSearchCV(xgb,params,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3aaa97da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "Best Score is : 0.763748419721871 \n",
      "\n",
      "\n",
      "0.64 + or -0.084 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.668 + or -0.073 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.687 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.687 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.683 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.659 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.677 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.683 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.685 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.685 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.677 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.678 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.684 + or -0.071 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.695 + or -0.067 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.696 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.697 + or -0.046 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.696 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.699 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.698 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.696 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.693 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.698 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.694 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.692 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.695 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.683 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.701 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.696 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.697 + or -0.065 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.701 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.591 + or -0.079 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.6 + or -0.083 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.616 + or -0.081 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.626 + or -0.086 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.628 + or -0.082 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.622 + or -0.063 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.609 + or -0.08 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.628 + or -0.071 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.64 + or -0.071 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.648 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.645 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.646 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.664 + or -0.077 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.671 + or -0.078 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.682 + or -0.08 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.66 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.673 + or -0.07 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.674 + or -0.062 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.68 + or -0.069 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.688 + or -0.069 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.663 + or -0.05 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.666 + or -0.053 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.672 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.688 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.694 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.684 + or -0.049 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.672 + or -0.068 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.683 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.689 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.698 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.573 + or -0.084 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.577 + or -0.093 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.58 + or -0.085 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.585 + or -0.081 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.587 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.6 + or -0.084 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.598 + or -0.085 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.605 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.601 + or -0.075 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.603 + or -0.072 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.639 + or -0.067 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.616 + or -0.084 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.626 + or -0.065 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.626 + or -0.071 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.629 + or -0.069 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.651 + or -0.065 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.638 + or -0.065 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.637 + or -0.057 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.636 + or -0.065 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.645 + or -0.066 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.662 + or -0.064 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.644 + or -0.061 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.643 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.648 + or -0.058 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.651 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.675 + or -0.059 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.653 + or -0.056 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.656 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.652 + or -0.06 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.658 + or -0.054 for the {'colsample_bytree': 0.3, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.662 + or -0.087 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.697 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.697 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.707 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.707 + or -0.065 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.698 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.712 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.722 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.725 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.731 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.713 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.724 + or -0.068 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.729 + or -0.064 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.735 + or -0.059 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.737 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.729 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.731 + or -0.056 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.735 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.738 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.739 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.735 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.743 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.741 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.743 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.746 + or -0.053 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.737 + or -0.047 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.738 + or -0.057 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.744 + or -0.051 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.745 + or -0.048 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.744 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.579 + or -0.082 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.621 + or -0.095 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.64 + or -0.098 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.655 + or -0.09 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.665 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.628 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.656 + or -0.093 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.665 + or -0.089 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.672 + or -0.087 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.687 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.684 + or -0.067 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.703 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.712 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.719 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.722 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.7 + or -0.052 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.721 + or -0.073 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.729 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.729 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.729 + or -0.069 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.72 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.724 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.735 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.732 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.729 + or -0.072 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.725 + or -0.058 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.729 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.732 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.735 + or -0.066 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.738 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.573 + or -0.082 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.573 + or -0.089 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.582 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.583 + or -0.075 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.592 + or -0.085 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.612 + or -0.09 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.618 + or -0.088 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.623 + or -0.089 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.625 + or -0.087 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.632 + or -0.086 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.676 + or -0.062 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.666 + or -0.071 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.673 + or -0.077 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.675 + or -0.078 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.676 + or -0.08 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.709 + or -0.049 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.705 + or -0.065 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.703 + or -0.076 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.7 + or -0.084 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.7 + or -0.079 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.725 + or -0.055 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.725 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.724 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.717 + or -0.082 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.717 + or -0.083 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.731 + or -0.054 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.729 + or -0.063 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.735 + or -0.065 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.728 + or -0.074 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.729 + or -0.07 for the {'colsample_bytree': 0.5, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.668 + or -0.097 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.711 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.714 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.708 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.715 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.696 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.722 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.74 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.727 + or -0.057 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.727 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.735 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.746 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.748 + or -0.044 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.746 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.745 + or -0.046 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.761 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.754 + or -0.058 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.755 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.755 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.757 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.748 + or -0.059 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.758 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.754 + or -0.054 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.754 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.753 + or -0.053 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.759 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.76 + or -0.052 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.763 + or -0.049 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.764 + or -0.051 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.764 + or -0.047 for the {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.569 + or -0.104 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.611 + or -0.079 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.64 + or -0.083 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.651 + or -0.086 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.659 + or -0.083 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.601 + or -0.084 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.656 + or -0.089 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.683 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.688 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.702 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.658 + or -0.078 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.704 + or -0.07 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.713 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.727 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.729 + or -0.06 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.709 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.722 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.733 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.745 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.751 + or -0.066 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.725 + or -0.07 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.729 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.736 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.734 + or -0.062 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.743 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.727 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.743 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.752 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.755 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.754 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 900}\n",
      "0.571 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "0.56 + or -0.076 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 300}\n",
      "0.566 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.562 + or -0.085 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 700}\n",
      "0.565 + or -0.093 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 900}\n",
      "0.595 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 100}\n",
      "0.594 + or -0.08 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 300}\n",
      "0.597 + or -0.093 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 500}\n",
      "0.598 + or -0.088 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 700}\n",
      "0.597 + or -0.089 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 900}\n",
      "0.631 + or -0.063 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 100}\n",
      "0.642 + or -0.061 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 300}\n",
      "0.65 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.648 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 700}\n",
      "0.656 + or -0.071 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 6, 'n_estimators': 900}\n",
      "0.671 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 100}\n",
      "0.686 + or -0.064 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 300}\n",
      "0.696 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 500}\n",
      "0.692 + or -0.068 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 700}\n",
      "0.698 + or -0.07 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 8, 'n_estimators': 900}\n",
      "0.685 + or -0.065 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n",
      "0.691 + or -0.074 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 300}\n",
      "0.694 + or -0.075 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 500}\n",
      "0.707 + or -0.07 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 700}\n",
      "0.709 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 900}\n",
      "0.691 + or -0.067 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100}\n",
      "0.693 + or -0.069 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 300}\n",
      "0.704 + or -0.073 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 500}\n",
      "0.712 + or -0.072 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 700}\n",
      "0.719 + or -0.07 for the {'colsample_bytree': 0.8, 'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee14c844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "XGBoost  average accuracy is 0.764\n",
      "XGBoost  average log_loss is 0.617\n",
      "XGBoost  average brier score is 0.181\n",
      "XGBoost  average auc is 0.841\n",
      "XGBoost  average recall is 0.845\n",
      "XGBoost  average precision is 0.729\n",
      "XGBoost  average f1 is 0.782\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier( objective= 'binary:logistic', nthread=4, seed=42, n_estimators=700,\n",
    "                   max_depth = 15, learning_rate = 0.1, colsample_bytree = 0.8)\n",
    "xgb.fit(X,Y)\n",
    "\n",
    "showResults(xgb, \"XGBoost\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4590817b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
